{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfejMHs4lr8V"
   },
   "source": [
    "*Copyright 2024 The Penzai Authors.*\n",
    "\n",
    "*Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at*\n",
    "\n",
    "> http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "*Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or  implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USGIPdLYDzSo"
   },
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google-deepmind/penzai/blob/main/notebooks/induction_heads.ipynb) [![Open in Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/google-deepmind/penzai/blob/main/notebooks/induction_heads.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGbQxydNslDn"
   },
   "source": [
    "# Induction Heads in Gemma 7B\n",
    "\n",
    "One of Penzai's primary goals is to support interpretability research on state-of-the-art models. In this notebook, we'll use Penzai to try to find and intervene on induction heads ([Elhage et al. 2021](https://transformer-circuits.pub/2021/framework/index.html#induction-heads), [Olsson et al. 2022](https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html)) in the [Gemma 7B](https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf) open-weights model.\n",
    "We'll be focusing on exploratory analysis and on Penzai's tooling rather than on rigor; the goal is to show how you can use Penzai to quickly prototype ideas and generate hypotheses about network behavior (not to perfectly measure the presence of induction heads or exactly reproduce previous results).\n",
    "\n",
    "Along the way, we'll discuss:\n",
    "\n",
    "- How to use JAX's sharding support to automatically shard the model over a cluster of TPUs,\n",
    "- How to use Penzai's pretty-printer (Treescope) to quickly look at model weights and activations,\n",
    "- How to extract intermediate values and intermediate subcomputations from a larger model for detailed analysis, using either Penzai's manual patching tool `pz.select` or using Penzai's data-effect system,\n",
    "- How to use Penzai's named axis library to identify the characteristic patterns of induction heads,\n",
    "- And how to patch the Gemma model by intervening on intermediate subcomputations (in this case, the attention weights),\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "*Note: This version of this tutorial uses the 7-billion parameter Gemma model, which requires an accelerator with at least 24GB+ of RAM. (Colab \"TPU v2\" or Kaggle TPU kernels should work.) For a version with a smaller memory footprint, see the [\"Induction Heads in Gemma 2B\"](induction_heads_2B.ipynb) tutorial, which covers the same material.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p77_8mr8uyp2"
   },
   "source": [
    "## Setting up and loading the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkW4lYKAu-oR"
   },
   "source": [
    "We'll start by setting up the environment and loading the Gemma 7B model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ozG8ERNavDos"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmxgAcFQmZkB"
   },
   "source": [
    "To run this notebook, you need a Python environment with `penzai` and its dependencies installed.\n",
    "\n",
    "In Colab or Kaggle, you can install it using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGZH58j8mPkj"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  import penzai\n",
    "except ImportError:\n",
    "  !pip install penzai[notebook]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iog3oMAMGCMG"
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Any\n",
    "\n",
    "import os\n",
    "import dataclasses\n",
    "import gc\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import orbax.checkpoint\n",
    "from jax.experimental import mesh_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ljCMQGV00mZ1"
   },
   "outputs": [],
   "source": [
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Mh2mAuiQ4aa"
   },
   "outputs": [],
   "source": [
    "import treescope\n",
    "import penzai\n",
    "from penzai import pz\n",
    "\n",
    "from penzai.models import transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGzhV5uWvkvB"
   },
   "source": [
    "### Setting up Penzai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjGkV8F8vmpi"
   },
   "source": [
    "For this tutorial, we'll enable [Treescope](https://treescope.readthedocs.io/en/stable/) (Penzai's companion pretty-printer) as the default Colab pretty-printer. We'll also turn on automatic visualization of JAX and Numpy arrays. This will make it easy to look at our models and their outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YodWk_jmva_7"
   },
   "outputs": [],
   "source": [
    "treescope.basic_interactive_setup(autovisualize_arrays=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ISnc54lwJIV"
   },
   "source": [
    "### Loading Gemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJbVbYBewKnm"
   },
   "source": [
    "Next we'll load the weights from the Gemma checkpoint. We'll use the 7B checkpoint for this tutorial.\n",
    "\n",
    "This notebook should work in any kernel with enough memory to load the 7B model, which includes Colab's \"TPU v2\" and \"A100\" kernels and Kaggle notebook TPU kernels. You can also run this using your own local GPU IPython runtime, either connected to Colab or a different IPython frontend.\n",
    "\n",
    "If you don't have access to an accelerator with enough memory, you can open the [\"Induction Heads in Gemma 2B\"](induction_heads_2B.ipynb) tutorial instead, which walks through the analysis for the smaller model and should work on a Colab T4 GPU kernel.\n",
    "(Both tutorials cover the same material, but the locations of the induction heads and some aspects of the model predictions differ between the variants!)\n",
    "\n",
    "When loading the arrays, we'll shard them over their last positional axis, which ensures that they fit in memory on the \"TPU v2\" kernel. JAX and the Orbax checkpointer automatically take care of partitioning the arrays across the devices and exposing a uniform interface to the sharded arrays. In fact, most operations on partitioned arrays \"just work\" without having to do anything special. (You can read more about JAX's automatic distributed arrays [on this JAX documentation page](https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html).)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0X3qrwbK4SvX"
   },
   "source": [
    "You can download the Gemma checkpoints using a Kaggle account and an API key. If you don't have an API key already, you can:\n",
    "\n",
    "1. Visit https://www.kaggle.com/ and create an account if needed.\n",
    "2. Go to your account settings, then the 'API' section.\n",
    "3. Click 'Create new token' to download your key.\n",
    "\n",
    "Next, if you are running this notebook in Google Colab:\n",
    "\n",
    "1. Click the \"key\" symbol on the left toolbar to open the \"Secrets\" tab.\n",
    "2. Add two new secrets, named \"KAGGLE_USERNAME\" and \"KAGGLE_KEY\", and set their values based on the API key you downloaded.\n",
    "3. Run the cell below and grant this notebook access to the secrets you just made.\n",
    "\n",
    "If you are not running this notebook in Google Colab, you can instead run the cell below, input your username and API key in the textboxes, and click the login button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uNgVlaJl2IbZ"
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "try:\n",
    "  from google.colab import userdata\n",
    "  kagglehub.config.set_kaggle_credentials(\n",
    "      userdata.get(\"KAGGLE_USERNAME\"), userdata.get(\"KAGGLE_KEY\")\n",
    "  )\n",
    "except ImportError:\n",
    "  kagglehub.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8Oxko4R4yaK"
   },
   "source": [
    "If everything went well, you should see:\n",
    "\n",
    "```\n",
    "Kaggle credentials set.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eUnej-yy5beB"
   },
   "source": [
    "Before downloading Gemma, you will also need to consent to the Gemma Terms of Use. If you haven't done that yet, you can do so here:\n",
    "\n",
    "> https://www.kaggle.com/models/google/gemma/license/consent\n",
    "\n",
    "(Make sure you choose to \"Verify via Kaggle Account\" with the same account you used to log in above!)\n",
    "\n",
    "Once you've agreed to the terms, you can run the next cell to download the Gemma weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BmUAGwXE41la"
   },
   "outputs": [],
   "source": [
    "weights_dir = kagglehub.model_download('google/gemma/Flax/7b')\n",
    "ckpt_path = os.path.join(weights_dir, '7b')\n",
    "vocab_path = os.path.join(weights_dir, 'tokenizer.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9nlbX3C-1sB6"
   },
   "source": [
    "We can then load the SentencePiece vocabulary and restore the checkpointed parameters into JAX using `orbax`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pEXnGmeUGxCK"
   },
   "outputs": [],
   "source": [
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.Load(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bn6Xwlk3xlr5"
   },
   "outputs": [],
   "source": [
    "checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n",
    "metadata = checkpointer.metadata(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VewGmKxMwIbs"
   },
   "outputs": [],
   "source": [
    "n_devices = jax.local_device_count()\n",
    "sharding_devices = mesh_utils.create_device_mesh((n_devices,))\n",
    "sharding = jax.sharding.PositionalSharding(sharding_devices)\n",
    "restore_args = jax.tree_util.tree_map(\n",
    "    lambda m: orbax.checkpoint.ArrayRestoreArgs(\n",
    "        restore_type=jax.Array,\n",
    "        sharding=sharding.reshape((1,) * (len(m.shape) - 1) + (n_devices,))\n",
    "    ),\n",
    "    metadata,\n",
    ")\n",
    "flat_params = checkpointer.restore(ckpt_path, restore_args=restore_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxJBci_exxj6"
   },
   "source": [
    "Let's take a look! Since we've registered Treescope as the default pretty-printer and turned on array visualization, we can just output the arrays from Colab and see a rich visualization of their values.\n",
    "\n",
    "Try clicking to explore the structure of the arrays below!\n",
    "\n",
    "*(Note: It may take a while for the array summaries to load the first time, because JAX has to compile the summarization code. You can still look at array shapes before they finish, and it should be faster to run the second time.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WBMJ54632bnN"
   },
   "outputs": [],
   "source": [
    "flat_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fPBZkOnv6xBo"
   },
   "source": [
    "The next step is to build the Gemma model using these weights. Since we're interested in studying model activations, we'll configure it to compute the activations in `float32` precision, even though the weight are stored in `bfloat16` precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g9amupev6WKj"
   },
   "outputs": [],
   "source": [
    "model = transformer.variants.gemma.gemma_from_pretrained_checkpoint(\n",
    "    flat_params,\n",
    "    upcast_activations_to_float32=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muJhjDGT989k"
   },
   "source": [
    "Let's look at it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XuJelwXb8Gvw"
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwc3C_Mw-p_I"
   },
   "source": [
    "Penzai models are designed to reveal as much information as possible when pretty printed. Try clicking the triangles to expand different layers, and look at the structure of the computation and of the parameters!\n",
    "\n",
    "We'll be taking a closer look at the attention layers later in this notebook. (If you'd like to learn more about the structure of this model, feel free to check out the code! You can click any pretty-printed output and press `r` to find the fully-qualified name of the class.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nxt4YxCZu1fP"
   },
   "outputs": [],
   "source": [
    "del flat_params\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iX39Iiqp_2eN"
   },
   "source": [
    "## Looking at outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGMr544mCPD1"
   },
   "source": [
    "Before we can look at the induction heads, we'll need to have some input to run it on. Taking inspiration from Olsson et al. (2021), let's try running the model on a repeated sequence of random tokens.\n",
    "\n",
    "The Gemma model is trained on natural text, so if we pick token IDs uniformly at random, it tends to get confused (since that's not a natural distribution over tokens). Instead, we'll run it on random numeric digits, which are likely to have shown up somewhere in the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "13n7RamcG7b5"
   },
   "outputs": [],
   "source": [
    "example_text = (\n",
    "    \"01976954310149754605\"\n",
    "    + \"01976954310149754605\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9wVPzFFDVOM"
   },
   "source": [
    "The Gemma tokenizer tokenizes each digit separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YY3rM0zwHKNd"
   },
   "outputs": [],
   "source": [
    "tokens = jnp.array([vocab.bos_id()] + vocab.EncodeAsIds(example_text))\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqw0kBdZHNNj"
   },
   "source": [
    "Treescope visualizes integer arrays using \"digitbox\" patterns, where each base-10 digit of the integer (in this case, of the token ID) is shown as a colored stripe. This can be used to visualize patterns across multiple examples. We can make the correspondence more visible by telling the autovisualizer about our tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JSRQW0LUHkz3"
   },
   "outputs": [],
   "source": [
    "%%autovisualize treescope.ArrayAutovisualizer.for_tokenizer(vocab)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsRSECsmHo4K"
   },
   "source": [
    "Try hovering or clicking on the above visualization; you should see the token ID and token string for each token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FfN3aKEheOX0"
   },
   "source": [
    "Next, let's tag it with axis names. Penzai includes a lightweight named-axis system, which allows you to associate names with arbitrary axes. There's a [separate tutorial](named_axes.ipynb) about how to use the named axis system, but the short version is:\n",
    "- Named arrays are represented using Python `pz.nx.NamedArray` dataclass, which is just a combination of an array and a sequence of axis names.\n",
    "- It's OK for only a subset of axes to have names. You can bind positional axes to names using `.tag(name1, name2, ...)`, and unbind names back into positional axes using `.untag(name1, name2, ...)`.\n",
    "- You can run ordinary JAX functions using `pz.nx.nmap` (e.g. `pz.nx.nmap(jax.nn.softmax)(array, axis=0)`). JAX functions *only see the positional axes*, and  automatically *vectorize* over named axes (using `jax.vmap` under the hood), so if you want to run it over a named axis you need to unbind the name first (e.g. `pz.nx.nmap(jax.nn.softmax)(array.untag(\"vocab\"), axis=0).tag(\"vocab\")`). You can also use array instance methods like `array.sum()`, but they again only operate over positional axes.\n",
    "\n",
    "We can wrap our token array like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t3wXtNxtKFaQ"
   },
   "outputs": [],
   "source": [
    "token_seq = pz.nx.wrap(tokens).tag(\"seq\")\n",
    "token_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwQGyXXzKKIl"
   },
   "source": [
    "Treescope knows how to visualize `NamedArray`s, so the \"axis 0\" annotation now shows as \"seq\".\n",
    "\n",
    "There are also some more complicated utilities for visualizing named arrays of tokens in particular:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ExZjlez0h7sH"
   },
   "outputs": [],
   "source": [
    "from penzai.toolshed import token_visualization\n",
    "token_visualization.show_token_array(token_seq, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7Ubz5qsh892"
   },
   "source": [
    "We can now call our model and look at the output log-probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FD6pjeh-Vj9n"
   },
   "outputs": [],
   "source": [
    "logits = model(token_seq)\n",
    "# Map softmax over the vocabulary\n",
    "log_probs = pz.nx.nmap(jax.nn.log_softmax)(\n",
    "    logits.untag(\"vocabulary\")\n",
    ").tag(\"vocabulary\")\n",
    "log_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFJV9hfMbSGB"
   },
   "source": [
    "We're most interested in the log-probabilities of the correct token, so let's look at those. To do this, we'll first slice off the first or last tokens, so that we align the previous step's prediction with the next step's ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xe6LsNzVcZZb"
   },
   "outputs": [],
   "source": [
    "# Indexing with a dictionary indexes the named axes; pz.slice helps slice them.\n",
    "sliced_preds = log_probs[{\"seq\": pz.slice[:-1]}]\n",
    "correct_next_token = token_seq[{\"seq\": pz.slice[1:]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdwvMqnGD78N"
   },
   "source": [
    "Then we'll index into the vocabulary axis using the correct tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bpDomgfZEDrp"
   },
   "outputs": [],
   "source": [
    "log_prob_of_correct_next = sliced_preds[{\"vocabulary\": correct_next_token}]\n",
    "log_prob_of_correct_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHE5QblVEJed"
   },
   "source": [
    "With Penzai's named axis system, axes with the same name always broadcast together. In this case, it matched up the \"seq\" axis in both arrays, which is indeed what we wanted.\n",
    "\n",
    "Note that the dictionary-style indexing of named arrays is syntactic sugar around lower-level tagging and indexing operations. We could have gotten the same result with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tAR8th48Eec3"
   },
   "outputs": [],
   "source": [
    "# Unbind the names, slice the positional array, rebind the names if needed.\n",
    "sliced_preds = log_probs.untag(\"seq\")[:-1].tag(\"seq\")\n",
    "correct_next_token = token_seq.untag(\"seq\")[1:].tag(\"seq\")\n",
    "sliced_preds.untag(\"vocabulary\")[correct_next_token]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2fcSB60qr10"
   },
   "source": [
    "Penzai provides some utilities for visualizing token scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ikru1gyDb_fY"
   },
   "outputs": [],
   "source": [
    "# Log probs (redder is smaller)\n",
    "token_visualization.show_token_scores(correct_next_token, log_prob_of_correct_next, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rnxg38EftfM5"
   },
   "outputs": [],
   "source": [
    "# Probabilities (bluer is larger)\n",
    "token_visualization.show_token_scores(correct_next_token, pz.nx.nmap(jnp.exp)(log_prob_of_correct_next), vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "do1PsrAhuQ3x"
   },
   "source": [
    "(Try hovering your mouse over the boxes!)\n",
    "\n",
    "We see that the model settles to around 5-10% accuracy for the first repetition of the sequence, then quickly ramps up to about 80-100% accuracy after seeing the first four digits of the repetition. Let's try to figure out how!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zq3B8r-oFEnI"
   },
   "source": [
    "## Looking at attention patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvdGjL9LFGUB"
   },
   "source": [
    "The first step to understanding the attention patterns used by Gemma is to extract what those patterns actually are. Penzai has a few different tools we can use for this. We'll start by showing how you could implement this logic yourself using Penzai's tree-rewriting utility `pz.select`, and then discuss higher-level wrappers that make this particular use case easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ec33aTIFpCt"
   },
   "source": [
    "### Injecting logic with `pz.select`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-j18OS6UFtmA"
   },
   "source": [
    "Penzai models are designed to be easy to patch in an interactive setting. In particular, it's easy to create copies of your model that include new bits of logic.\n",
    "\n",
    "Penzai's primary tool for manipulating the structure of Python objects is `pz.select`. This can be used to identify parts of an object you want to change, and then make changes to it. Under the hood, it's built on top of `jax.tree_util`, so it works on any type that's been registered with JAX. You can use it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9So6jZCMKHGx"
   },
   "outputs": [],
   "source": [
    "my_list = [1, 2, \"Hello \", 4]\n",
    "\n",
    "# Append something to all strings:\n",
    "my_patched_list = (\n",
    "    pz.select(my_list).at_instances_of(str).apply(lambda s: s + \"World!\")\n",
    ")\n",
    "\n",
    "# my_list isn't modified:\n",
    "pz.show(\"my_list:\", my_list)\n",
    "\n",
    "# But my_patched_list includes our change:\n",
    "pz.show(\"my_patched_list:\", my_patched_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wOYctpl2Lvuq"
   },
   "source": [
    "`pz.select` produces a `Selection` object that tracks a particular part (or parts) of a larger structure. We can print them out to see what part is selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EwysSzk2LvGV"
   },
   "outputs": [],
   "source": [
    "pz.select(my_list).at_instances_of(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGlp473cLWQP"
   },
   "source": [
    "There are a lot of different ways to build and manipulate `Selection`s. Another useful thing you can do is pass a function that picks out a particular subtree of your tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R87gGSw_MPvN"
   },
   "outputs": [],
   "source": [
    "pz.select(my_list).at(lambda root: root[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJhCNvMoMen4"
   },
   "source": [
    "*(Aside: You may have noticed the little grey \"copy\" buttons next to each line of a treescope rendering. If you click one of those, it will copy a function that picks out that subtree, which can be useful either for extracting the value or for passing to `pz.select(...).at(...)`.)*\n",
    "\n",
    "See the separate [\"Selectors\" tutorial](selectors.ipynb) for details about the operations `pz.select` supports! For now, we'll discuss the features we need as we use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYj_ADk1KiTJ"
   },
   "source": [
    "\n",
    "\n",
    "Recall again our model object. We can use `pz.select` to identify a specific attention block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s14Cwn_aLHku"
   },
   "outputs": [],
   "source": [
    "%%autovisualize None\n",
    "\n",
    "selected = (\n",
    "    pz.select(model)\n",
    "    .at_instances_of(pz.nn.Attention)\n",
    "    .pick_nth_selected(1)\n",
    "    .at_instances_of(pz.nn.Softmax)\n",
    ")\n",
    "selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-L9114pJc3Q"
   },
   "source": [
    "In Penzai models, the pretty-printed representation isn't just a summary of what's inside your model, it's actually a *complete specification of all of the steps that occur when your model runs*. So, if we insert something new into our model using `pz.select`, the resulting model will run the logic we inserted along with the rest of its operations!\n",
    "\n",
    "For instance, let's define a simple layer that shows its intermediate value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PhF0WLIgNxI5"
   },
   "outputs": [],
   "source": [
    "@pz.pytree_dataclass  # <- This tags our class as being a Python dataclass and a JAX pytree node.\n",
    "class DisplayIntermediateValue(pz.nn.Layer):  # <- pz.nn.Layer is the base class of Penzai layers.\n",
    "  def __call__(self, intermediate_value, **unused_side_inputs):\n",
    "    # Show the value:\n",
    "    pz.show(\"Showing an intermediate value:\", intermediate_value)\n",
    "    # And return it unchanged.\n",
    "    return intermediate_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8zekyY_ON2X"
   },
   "source": [
    "By convention:\n",
    "- Every layer is a [Python dataclass](https://docs.python.org/3/library/dataclasses.html) and a [JAX pytree](https://jax.readthedocs.io/en/latest/pytrees.html). This makes it easy for JAX and Penzai tools to understand it.(However, layers may contain mutable `pz.Parameter` and `pz.StateVariable` attributes)\n",
    "- Most model components are subclasses of the abstract base class `pz.nn.Layer`, which means that they must define `__call__`. To allow composing together multiple layers, `__call__` always takes a single positional argument as input, which was usually the output of a previous layer. (They can also accept keyword \"side inputs\", which are passed down from parent layers to their children.)\n",
    "\n",
    "(You can read more about Penzai's conventions in the [\"How to Think in Penzai\"](how_to_think_in_penzai.ipynb) notebook!)\n",
    "\n",
    "Let's instantiate our layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kLfvR4G1PFz-"
   },
   "outputs": [],
   "source": [
    "DisplayIntermediateValue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m83RW0kbPHUr"
   },
   "source": [
    "And call it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wH9juTP4PIuM"
   },
   "outputs": [],
   "source": [
    "layer = DisplayIntermediateValue()\n",
    "output = layer(123)\n",
    "pz.show(\"Final:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lmc_6Cn7PU9X"
   },
   "source": [
    "Now let's try inserting our new layer into the Gemma model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_NhpC0sSPaFf"
   },
   "outputs": [],
   "source": [
    "%%autovisualize None\n",
    "\n",
    "# Make a patched copy of our model:\n",
    "patched = (\n",
    "    pz.select(model)\n",
    "    .at_instances_of(pz.nn.Attention)\n",
    "    .pick_nth_selected(1)\n",
    "    .at_instances_of(pz.nn.Softmax)\n",
    "    .insert_after(DisplayIntermediateValue())\n",
    ")\n",
    "\n",
    "# Find the thing we inserted into it:\n",
    "pz.select(patched).at_instances_of(DisplayIntermediateValue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYyu36LGQDkW"
   },
   "source": [
    "You might notice that the new `DisplayIntermediateValue()` layer is inside a layer called `Sequential`. `Sequential` is a layer combinator that runs all of it's children in sequence, passing the output of one layer to the input of the next. So inserting `DisplayIntermediateValue` here means it will receive the output of the softmax as its own input, and its own output will be returned as the final answer of `query_key_to_attn`. In fact, `GemmaAttention` is also a layer combinator; it simply combines the outputs from `query_key_to_attn` and `input_to_value` and passes them to the `attn_value_to_output` layer.\n",
    "\n",
    "By convention, idiomatic Penzai models generally express as much as possible in terms of these layer combinators, and defer the actual logic to small primitive layers like `Softmax` or `ApplyAttentionMask`. Structuring models this way naturally exposes all of the parts of the model that we might want to inspect or modify, making it easy to insert new logic like we've just done.\n",
    "\n",
    "If we call our new patched copy of the model, we get to see a summary of the attention weights, pretty-printed by the default renderer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ELB2_1jRab_"
   },
   "outputs": [],
   "source": [
    "patched(token_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKx64UQWRjU-"
   },
   "source": [
    "Looks like we successfully intercepted the attention weights! However, since the full matrix is quite big, treescope has automatically truncated it to save space and to avoid sending huge amounts of data. This means it's only showing ten of the 16 heads, and only the first and last eight tokens of the query and key/value axes, with dark shading indicating missing values.\n",
    "\n",
    "*(Sidenote: We haven't actually modified the original model. Calling it still runs the original logic and thus doesn't print out the attention matrices:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MIdbmJ4USNRl"
   },
   "outputs": [],
   "source": [
    "model(token_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cEbLh1daSWSt"
   },
   "source": [
    "*Nevertheless, the two models are sharing the same accelerator memory, because `pz.select` re-uses parts of the structure that haven't changed.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgoyhk8nQWPp"
   },
   "source": [
    "### Extracting an intermediate using `pz.StateVariable`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1n3lxg0TCZm"
   },
   "source": [
    "Let's try instead actually pulling the value out. To do that, we'll write a layer that stores it's activation inside one of its own attributes when it runs.\n",
    "\n",
    "Using mutable state requires a bit of care in Penzai. In order to make sure things work well with JAX's function transformations, Penzai follows these rules:\n",
    "\n",
    "- Every subclass of `pz.nn.Layer` is immutable, so you can't change its attributes directly. Instead, mutable state should be kept in a `pz.StateVariable`, stored as an attribute of the layer.\n",
    "- Layers should not \"close over\" mutable global state. In other words, a layer shouldn't reference any Python variables from an outer Python scope that contain mutable objects (like dictionaries or lists). Instead, they should only read and modify their own `pz.StateVariable` attributes.\n",
    "  - (It's OK for the `pz.StateVariable` to be used outside the model, as long as the layer implementation only accesses it through its own attribute. This is because Penzai needs to be able to identify which variables a layer might modify.)\n",
    "\n",
    "\n",
    "For instance, we can define this layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sX5WYjqpSV_R"
   },
   "outputs": [],
   "source": [
    "@pz.pytree_dataclass\n",
    "class SaveIntermediate(pz.nn.Layer):\n",
    "  saved: pz.StateVariable[Any | None]\n",
    "  def __call__(self, value: Any, /, **_unused_side_inputs) -> Any:\n",
    "    self.saved.value = value\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvR8MlS7RJUF"
   },
   "source": [
    "Insert it into our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t2THLZfVROdv"
   },
   "outputs": [],
   "source": [
    "destination = pz.StateVariable(value=None)\n",
    "destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SG_n3E92R6Ab"
   },
   "outputs": [],
   "source": [
    "patched_model = (\n",
    "    pz.select(model)\n",
    "    .at_instances_of(pz.nn.Attention)\n",
    "    .pick_nth_selected(1)\n",
    "    .at_instances_of(pz.nn.Softmax)\n",
    "    .insert_after(SaveIntermediate(destination))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMYxcpLsRdoA"
   },
   "source": [
    "Run the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_7084go9Ref2"
   },
   "outputs": [],
   "source": [
    "patched_model(token_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXDFW7NvRhWP"
   },
   "source": [
    "And then retrieve the value from our saved output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "585LeKkaRjcO"
   },
   "outputs": [],
   "source": [
    "destination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIRGtTxiZ1KB"
   },
   "source": [
    "Now that we have direct access to the attention pattern, we can inspect it in more detail. We can use `treescope.render_array`, which produces the same type of figure as the default autovisualizer, but gives us control over how it renders things:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fpNGigfJaFzB"
   },
   "outputs": [],
   "source": [
    "treescope.render_array(\n",
    "    destination.value,\n",
    "    truncate=False,  # <- False is the default value, but it's True in the autovisualizer\n",
    "    # This adds the actual token values to the hover tooltips:\n",
    "    axis_item_labels={\n",
    "        \"seq\": [repr(vocab.IdToPiece(int(t))) for t in tokens],\n",
    "        \"kv_seq\": [repr(vocab.IdToPiece(int(t))) for t in tokens],\n",
    "    },\n",
    "    # Put query position on the Y axis.\n",
    "    rows=[\"seq\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKxc7VSyHIMN"
   },
   "source": [
    "We can see a few different behaviors here. Head 2 appears to be attending to \"two tokens back\". Head 3 seems to attend to every previous occurence of each token. And many of the other layers seem to be doing something \"fuzzier\", falling back to attending to the beginning-of-sequence token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2hxLNda8u7zA"
   },
   "outputs": [],
   "source": [
    "del destination, patched_model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3jSUsP_HbBG"
   },
   "source": [
    "### Extracting many intermediates at once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dj0tRwJXSdG_"
   },
   "source": [
    "We can use this general approach to capture many different intermediates at the same time. To do this, we'll insert a copy of `SaveIntermediate` with a fresh variable after *every* softmax layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jVwshCr-SrFG"
   },
   "outputs": [],
   "source": [
    "softmax_saving_model = (\n",
    "    pz.select(model)\n",
    "    .at_instances_of(pz.nn.Attention)\n",
    "    .at_instances_of(pz.nn.Softmax)\n",
    "    # Replace each [..., Softmax, ...] sequence with\n",
    "    # the new sequence [..., Softmax, SaveIntermediate(var), ...].\n",
    "    # (We don't use `insert_after` because it will insert copies of\n",
    "    # the same variable, which we don't want.)\n",
    "    .apply_and_inline(\n",
    "        lambda l: [l, SaveIntermediate(pz.StateVariable(None))]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHWnUESdT8wr"
   },
   "source": [
    "We can find these in the model to see where they are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUBkoTmkT-gU"
   },
   "outputs": [],
   "source": [
    "pz.select(softmax_saving_model).at_instances_of(SaveIntermediate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4xRxCEIUFyK"
   },
   "source": [
    "Each time we create a new `pz.StateVariable`, it gets a fresh label. Penzai uses this to ensure that variables don't conflict with each other. If you want, you can also pass a custom label using the `label` keyword argument (e.g. `pz.StateVariable(..., label=...)`). If you accidentally give two variables the same label, you may get an error later when trying to use your model with JAX transformations.\n",
    "\n",
    "Now we can call the model, and then extract all the saved values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iZ88EiJRU0wj"
   },
   "outputs": [],
   "source": [
    "_ = softmax_saving_model(token_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7gQnqPDVU2iR"
   },
   "outputs": [],
   "source": [
    "collected_out = [\n",
    "    saver.saved.value\n",
    "    for saver in (\n",
    "        pz.select(softmax_saving_model)\n",
    "        .at_instances_of(SaveIntermediate)\n",
    "        .get_sequence()\n",
    "    )\n",
    "]\n",
    "collected_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTMW6eU5P2NT"
   },
   "source": [
    "Each entry in `collected_out` is the value of the variable saved by one of our new `SaveIntermediates` layers. Let's stack all the attention masks together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7HV4N39-QiCW"
   },
   "outputs": [],
   "source": [
    "all_attentions = pz.nx.stack(collected_out, \"blocks\")\n",
    "# ^ shorthand for nmap(jnp.stack)(collected_out).tag(\"blocks\")\n",
    "del softmax_saving_model, collected_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOL_NTwTT2Vs"
   },
   "source": [
    "And let's look at them!\n",
    "\n",
    "*Treescope tip for viewing large arrays: Holding Alt and scrolling will zoom in or out, and Shift+scrollwheel scrolls you along the X-axis instead of the Y-axis.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rkMQP1GmT1xA"
   },
   "outputs": [],
   "source": [
    "simple_causal_mask = (\n",
    "    # Queries can attend to keys that come before them.\n",
    "    pz.nx.arange(\"kv_seq\", token_seq.named_shape[\"seq\"])\n",
    "    <= pz.nx.arange(\"seq\", token_seq.named_shape[\"seq\"])\n",
    ")\n",
    "\n",
    "treescope.render_array(\n",
    "    all_attentions,\n",
    "    # Annotate the sequence axes with the token names:\n",
    "    axis_item_labels={\n",
    "        \"seq\": [repr(vocab.IdToPiece(int(t))) for t in tokens],\n",
    "        \"kv_seq\": [repr(vocab.IdToPiece(int(t))) for t in tokens],\n",
    "    },\n",
    "    # Customize the row/column assignments\n",
    "    rows=[\"seq\", \"blocks\"], columns=[\"kv_seq\", \"heads\"],\n",
    "    # Overlay a causal mask:\n",
    "    valid_mask=simple_causal_mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hx4IC35D6Y6F"
   },
   "source": [
    "Can you spot any interesting behavior? A few thinks you can look for:\n",
    "\n",
    "- Heads that attend a fixed offset back from the current token\n",
    "- Heads that attend to previous occurrences of the same token\n",
    "- Heads that seem to find a single token and attend to it throughout the sequence\n",
    "- Heads that have different behavior on the second repetition of the first\n",
    "  - In particular, can you find any possible induction heads: Heads that attend to repeated tokens but shifted by one, so that they are attending to the token that will come next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZquZivmVmyS"
   },
   "source": [
    "Note: This isn't the only way to capture intermediate values! For instance, we could have instead made a single variable that stores a tuple of intermediate values, then added to it, using something like\n",
    "\n",
    "```python\n",
    "@pz.pytree_dataclass\n",
    "class AppendIntermediate(pz.nn.Layer):\n",
    "  saved: pz.StateVariable[tuple[Any]]\n",
    "  def __call__(self, value: Any, /, **_unused_side_inputs) -> Any:\n",
    "    self.saved.value = self.saved.value + (value,)\n",
    "    return value\n",
    "\n",
    "destination = pz.StateVariable(())\n",
    "softmax_saving_model_2 = (\n",
    "    pz.select(model)\n",
    "    .at_instances_of(pz.nn.Attention)\n",
    "    .at_instances_of(pz.nn.Softmax)\n",
    "    .insert_after(AppendIntermediate(destination))\n",
    ")\n",
    "_ = softmax_saving_model_2(token_seq)\n",
    "\n",
    "pz.nx.stack(destination.value, \"blocks\")\n",
    "```\n",
    "\n",
    "As long as you only modify `pz.StateVariable` attributes, you are free to implement your own layer logic for your own analysis needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Slm2qpCCWDR"
   },
   "source": [
    "## Identifying induction heads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y1aNqo5Q7sq8"
   },
   "source": [
    "Let's focus in our search on induction heads. Briefly summarizing the definition of an induction head from [Elhage et al. (2021)](https://transformer-circuits.pub/2021/framework/index.html#induction-heads) and [Olsson et al. (2022)](https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html), an induction head:\n",
    "\n",
    "- Finds a previous occurence of the current token (or, at a more abstract level, a previous repetition of the current sequence content)\n",
    "- Attends to the token *after* the previous occurence\n",
    "- Increases the likelihood of repeating the token it attended to (which, if the pattern continues, would also be the token after the current one)\n",
    "\n",
    "Our digit sequence is of length 20. So, we're looking for attention heads that attend 19 tokens back, e.g. when given the 25th token as input, they'd find the previous repetition (token 5) and attend to the *next* one (token 6).\n",
    "\n",
    "Let's try swapping the facet order of the above plot. On the outside, we'll show the two sequences, and in each inner facet, we'll show the matrix of blocks and heads. Each inner 2D rectangle will then be a \"fingerprint\" of all of the different attention heads that attended between the two given tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JW2bo5Gj9DJN"
   },
   "outputs": [],
   "source": [
    "treescope.render_array(\n",
    "    all_attentions,\n",
    "    axis_item_labels={\n",
    "        \"seq\": [repr(vocab.IdToPiece(int(t))) for t in tokens],\n",
    "        \"kv_seq\": [repr(vocab.IdToPiece(int(t))) for t in tokens],\n",
    "    },\n",
    "    # Swap row and column order\n",
    "    rows=[\"blocks\", \"seq\"], columns=[\"heads\", \"kv_seq\"],\n",
    "    valid_mask=simple_causal_mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdi3TFnz9d7m"
   },
   "source": [
    "Let's focus on the part of the attention matrix where the query is in the second repetition, and the keys are in the first (e.g. the bottom left quadrant of the above plot). We'll slice the matrices to just look at the first ten tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yM3VGAQ-91Q3"
   },
   "outputs": [],
   "source": [
    "treescope.render_array(\n",
    "    all_attentions[{\"seq\": pz.slice[20:30], \"kv_seq\": pz.slice[0:10]}],\n",
    "    axis_item_labels={\n",
    "        \"seq\": [repr(vocab.IdToPiece(int(t))) for t in tokens[20:30]],\n",
    "        \"kv_seq\": [repr(vocab.IdToPiece(int(t))) for t in tokens[0:10]],\n",
    "    },\n",
    "    rows=[\"blocks\", \"seq\"], columns=[\"heads\", \"kv_seq\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1f8hKdXI-JXY"
   },
   "source": [
    "We're looking for attention heads that attend \"one in the future\" relative to the repetition. Since \"seq\" is on the (outer) Y axis and \"kv_seq\" is on the (outer) X axis, that means we're looking for attention heads that are active \"one to the right of the block diagonal\", because they are attending to the *next* key/value token relative to the query.\n",
    "\n",
    "Interestingly, we can see some clear patterns in the fingerprints. There seems to be a fairly consistent set of heads that are active along the diagonal, and a different set of heads that are consistently active one above the diagonal. Perhaps these are inductions heads!\n",
    "\n",
    "If you hover or click on the high-intensity elements above the block diagonal (e.g. in the facet in the right column and second-to-bottom row),\n",
    "treescope will show you the named axes that this element corresponds to. Some possible candidates as induction heads:\n",
    "- {'blocks':5, 'heads':0}\n",
    "- {'blocks':14, 'heads':15}\n",
    "- {'blocks':20, 'heads':13}\n",
    "- {'blocks':21, 'heads':2}\n",
    "- {'blocks':21, 'heads':5}\n",
    "\n",
    "Let's slice the matrix so we can focus on the off-diagonal we're interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VzwR0E8rAWfI"
   },
   "outputs": [],
   "source": [
    "# Start one after the BOS token\n",
    "offset = pz.nx.wrap(jnp.arange(1, 21)).tag(\"offset\")\n",
    "# Query is offset + 20 (the second repetition)\n",
    "# Key is offset + 1 (the token after the first repetition)\n",
    "induction_off_diagonal = all_attentions[{\"seq\": offset + 20, \"kv_seq\": offset + 1}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q4OYsFC5AsXx"
   },
   "outputs": [],
   "source": [
    "treescope.render_array(induction_off_diagonal, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdxqqU-6ARwi"
   },
   "source": [
    "We're looking for heads that consistently attend along this extracted diagonal. Above, this will look like solid \"stripes\" along the `offset` axis, for a particular block and head index.\n",
    "\n",
    "Something interesting you might observe: Of the heads that seem to activate here, most seem to have a \"delay\" of one or two tokens before they activate, even though the token at offset 0 is already a repetition. Any guesses why?\n",
    "\n",
    "Let's summarize the stripes by taking an average over the `offset` dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MrRjp22ACG_z"
   },
   "outputs": [],
   "source": [
    "off_diagonal_avg = induction_off_diagonal.untag(\"offset\").mean()\n",
    "off_diagonal_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-HALaMtCNjr"
   },
   "source": [
    "This is a summary of how \"induction-head-like\" these attention patterns are. Let's sort them based on these scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qj3PWdnVCUWk"
   },
   "outputs": [],
   "source": [
    "# Convert back to positional, flatten, and sort:\n",
    "positional_avgs = off_diagonal_avg.untag(\"blocks\", \"heads\").unwrap()\n",
    "flat_avgs = positional_avgs.reshape([-1])\n",
    "block_index, head_index = jnp.unravel_index(jnp.argsort(flat_avgs)[::-1], positional_avgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Y5jNAYcDjBh"
   },
   "outputs": [],
   "source": [
    "for i, (bi, hi) in enumerate(zip(block_index, head_index)):\n",
    "  val = positional_avgs[bi, hi]\n",
    "  print(i, \"block:\", bi, \"head:\", hi, \"score:\", val)\n",
    "  if val < 0.1:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCZgre3wEUkw"
   },
   "source": [
    "Let's look at the attention patterns of these candidates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3dQT5AwkEY8-"
   },
   "outputs": [],
   "source": [
    "top_block_indices = pz.nx.wrap(block_index[:10]).tag(\"best_heads\")\n",
    "top_head_indices = pz.nx.wrap(head_index[:10]).tag(\"best_heads\")\n",
    "top_attn_patterns = all_attentions[{\"blocks\": top_block_indices, \"heads\": top_head_indices}]\n",
    "treescope.render_array(\n",
    "    top_attn_patterns,\n",
    "    vmax=1,\n",
    "    rows=[\"seq\"],\n",
    "    valid_mask=simple_causal_mask,\n",
    "    axis_item_labels={\n",
    "        \"seq\": [repr(vocab.IdToPiece(int(t))) for t in tokens],\n",
    "        \"kv_seq\": [repr(vocab.IdToPiece(int(t))) for t in tokens],\n",
    "        # Add info on which candidate this is to the hover tooltip:\n",
    "        \"best_heads\": {\n",
    "          i: f\"block {block_index[i]} head {head_index[i]}\" for i in range(10)\n",
    "        },\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IReKyiJ5E-gg"
   },
   "source": [
    "Looks like the first roughly six candidates we identified are crisply attending to the token that should be copied (the one right after the previous repetition), which is what we'd predict an induction head would do. The other ones seem to be attending more fuzzily.\n",
    "\n",
    "Interestingly, during the first repetition of the sequence, many of these heads also seem to attend to `{'seq':12, 'kv_seq':3}`, `{'seq':15, 'kv_seq':5}`, and `{'seq':17, 'kv_seq':9}`, albeit somewhat weakly. What are these tokens?\n",
    "\n",
    "If you hover over the cell immediately to the left of them, you'll see that these are internal repetitions in the original sequence! So these heads are looking tokens that appear after repetitions of the current token, even when that doesn't help predict the sequence (yet).\n",
    "\n",
    "```\n",
    "     kv_seq:3  seq:12\n",
    "        \n",
    "               \n",
    "<bos> 01976954310149754605 01976954310149754605\n",
    "\n",
    "       kv_seq:5   seq:15\n",
    "          \n",
    "                  \n",
    "<bos> 01976954310149754605 01976954310149754605\n",
    "\n",
    "          kv_seq:9  seq:17\n",
    "              \n",
    "                    \n",
    "<bos> 01976954310149754605 01976954310149754605\n",
    "```\n",
    "\n",
    "This seems like confirmatory evidence that these are induction heads!\n",
    "\n",
    "It also suggests a conjecture: perhaps the reason these heads do not immediately activate at token 21 (the first repeated token) and instead start becoming strongly active around token 22 or 23 is that sequence has already included spurious digit repetitions that *aren't* copied. Maybe some circuit is detecting this and inhibiting the induction heads until there's evidence that copying is actually happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i7Zim3q8vQvx"
   },
   "outputs": [],
   "source": [
    "del all_attentions\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IG4uSS37CX-A"
   },
   "source": [
    "## Intervening on attention patterns and activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ms-0uR_OK3uR"
   },
   "source": [
    "If these are really induction heads, we should expect them to actually *copy* the value of the token they attend to. How can we test whether or not this is happening?\n",
    "\n",
    "We could formalize this question in a few different ways. Some concrete questions:\n",
    "- If we drop these attention heads from the model entirely, does the model lose its ability to predict these tokens?\n",
    "- If we locally perturb these attention heads to make them attend to their target tokens *less*, does the model's overall accuracy go down?\n",
    "- Assuming these heads are improving accuracy, does that happen because they directly adjust the residual stream in the direction of the correct token, or because they copy information used by later attention heads, or because they copy information used by later MLP layers?\n",
    "\n",
    "Let's try to figure it out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AoDEV3mvpkTO"
   },
   "source": [
    "### Simple ablation: Knocking out attention heads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOa9xGAqqLUM"
   },
   "source": [
    "A simple thing we could try would be to just disable a subset of the heads, and see what happens to the model's predictions. If we're right that these are induction heads, we should expect that disabling them will reduce the model's predictive accuracy.\n",
    "\n",
    "How should we disable a head? One idea would be to zero-out its attention scores, but that might cause the activations to go out of distribution. As an alternative, recall that the (candidate) induction heads above seem to attend preferentially to the beginning-of-sequence token when there is nothing to copy. That suggests that a natural \"default value\" we could patch in would be to force the head to attend to the beginning-of-sequence token.\n",
    "\n",
    "(Note that attention heads are a particularly easy part of the model to patch like this! For other intermediate values where there isn't a sensible default, we might consider swapping in activations from a different input sequence (\"activation patching\", [Meng et al. 2021](https://arxiv.org/abs/2202.05262)) or swapping in an average of activations across many sequences (\"mean ablation\", [Wang et al. 2022](https://arxiv.org/abs/2211.00593)).)\n",
    "\n",
    "Here's a layer that will do the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x1Uznnz8sBSM"
   },
   "outputs": [],
   "source": [
    "@pz.pytree_dataclass\n",
    "class KnockOutAttentionHeads(pz.nn.Layer):\n",
    "  \"\"\"Layer that redirects masked-out heads to attend to BOS.\n",
    "\n",
    "  Attributes:\n",
    "    head_mask: NamedArray with 1s for heads we want to keep, and 0s for heads\n",
    "      that should be rewritten to point to BOS. Values between 0 and 1 will\n",
    "      smoothly interpolate between them.\n",
    "  \"\"\"\n",
    "  head_mask: pz.nx.NamedArray\n",
    "\n",
    "  def __call__(self, attn_weights: pz.nx.NamedArray, **side_inputs) -> pz.nx.NamedArray:\n",
    "    knocked_out_attn = pz.nx.wrap(\n",
    "        jnp.zeros(\n",
    "            [attn_weights.named_shape[\"kv_seq\"]],\n",
    "            attn_weights.dtype,\n",
    "        ).at[0].set(1.0)\n",
    "    ).tag(\"kv_seq\")\n",
    "    return knocked_out_attn + self.head_mask * (attn_weights - knocked_out_attn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3pVdQi-smU9"
   },
   "source": [
    "We can use it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_5bEsdNusk8d"
   },
   "outputs": [],
   "source": [
    "# Knock out every other head\n",
    "knockout_layer = KnockOutAttentionHeads(\n",
    "    head_mask=pz.nx.wrap(jnp.array(\n",
    "        [1,0,1,0,1,0,1,0,1,0]\n",
    "    ).astype(jnp.bfloat16)).tag(\"best_heads\")\n",
    ")\n",
    "\n",
    "# Show the results (which should alternate kept and knocked-out)\n",
    "treescope.render_array(\n",
    "    knockout_layer(top_attn_patterns),\n",
    "    vmax=1,\n",
    "    rows=[\"seq\"],\n",
    "    valid_mask=simple_causal_mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "og2mGI9YtIC5"
   },
   "source": [
    "Let's insert it into our model! We'll use a helper function to automate the process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fL3Q0f4qtway"
   },
   "outputs": [],
   "source": [
    "def knock_out_heads(model, head_mask_per_block):\n",
    "  parts = list(head_mask_per_block.untag(\"blocks\"))\n",
    "  return (\n",
    "      pz.select(model)\n",
    "      .at_instances_of(pz.nn.Attention)\n",
    "      .at_instances_of(pz.nn.Softmax)\n",
    "      .insert_after(\"<placeholder>\", and_select=True)  # <- Inserting a dummy object and selecting it so we can use `set_sequence`\n",
    "      .set_sequence(\n",
    "          KnockOutAttentionHeads(part) for part in parts\n",
    "      )\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHPq-KCGyPL3"
   },
   "source": [
    "Let's start by knocking out all ten of the possible induction heads we found earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UPnmOykFyTkd"
   },
   "outputs": [],
   "source": [
    "top_heads_mask = pz.nx.wrap(\n",
    "    jnp.ones(positional_avgs.shape, dtype=jnp.bfloat16)\n",
    "    .at[block_index[:10], head_index[:10]]\n",
    "    .set(0.0)\n",
    ").tag(\"blocks\", \"heads\")\n",
    "top_heads_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3fodfU3X05Zd"
   },
   "outputs": [],
   "source": [
    "%%autovisualize None\n",
    "\n",
    "ablated_model = knock_out_heads(model, top_heads_mask)\n",
    "pz.select(ablated_model).at_instances_of(KnockOutAttentionHeads).at_instances_of(pz.nx.NamedArray).show_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Lt44fbm1t61"
   },
   "source": [
    "Now we can try running it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4uhtOgQu1y9P"
   },
   "outputs": [],
   "source": [
    "ablated_logits = ablated_model(token_seq)\n",
    "# Map softmax over the vocabulary\n",
    "ablated_log_probs = pz.nx.nmap(jax.nn.log_softmax)(ablated_logits.untag(\"vocabulary\")).tag(\"vocabulary\")\n",
    "# Identify correct log probs\n",
    "ablated_sliced_preds = ablated_log_probs[{\"seq\": pz.slice[:-1]}]\n",
    "correct_next_token = token_seq[{\"seq\": pz.slice[1:]}]\n",
    "ablated_log_prob_of_correct_next = ablated_sliced_preds[{\"vocabulary\": correct_next_token}]\n",
    "ablated_log_prob_of_correct_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_yCBJCO91y9W"
   },
   "outputs": [],
   "source": [
    "# Log probs (redder is smaller)\n",
    "token_visualization.show_token_scores(correct_next_token, ablated_log_prob_of_correct_next, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i9fgccNP1y9W"
   },
   "outputs": [],
   "source": [
    "# Probabilities (bluer is larger)\n",
    "token_visualization.show_token_scores(correct_next_token, pz.nx.nmap(jnp.exp)(ablated_log_prob_of_correct_next), vocab, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oy4SgEZI2Biv"
   },
   "source": [
    "Comparing this to the original accuracies, it's clear that we've severely crippled the ability of the model to imitate the repeating pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XUqxtRMD1vNK"
   },
   "outputs": [],
   "source": [
    "token_visualization.show_token_scores(correct_next_token, pz.nx.nmap(jnp.exp)(log_prob_of_correct_next), vocab, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SryMAiGc5A0t"
   },
   "source": [
    "Does this apply to other types of sequence too? Let's try.\n",
    "\n",
    "Since our ablated model is an independent copy of our model (only sharing parameters), we are free to call both models on new inputs without having to worry about mutable state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eBAXxN-F9afg"
   },
   "outputs": [],
   "source": [
    "extra_examples = []\n",
    "\n",
    "# Some other random digit sequences:\n",
    "for i in range(100, 104):\n",
    "  s = \"\".join(str(i) for i in jax.random.choice(jax.random.key(i), jnp.arange(10), (20,)))\n",
    "  extra_examples.append(s + s)\n",
    "\n",
    "# Some other types of repetition:\n",
    "extra_examples.extend([\n",
    "    \" \".join(\"injunction double scamp cosmic stroll lucrative\" for _ in range(5)),\n",
    "    \"France: Paris, Chile: Santiago, Greece: Athens, China: Beijing, Belgium: Brussels, Norway: Oslo, Canada: Ottawa, Croatia: Zagreb, Algeria: Algiers\",\n",
    "    \"The west palace gate has fallen! I repeat, the west palace gate has fallen! We must fall back! I repeat, we must fall back!\",\n",
    "])\n",
    "\n",
    "# A number the model has probably memorized:\n",
    "extra_examples.append(\"3.1415926535897932384626433832795028841\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQR9WSjJ5D0C"
   },
   "outputs": [],
   "source": [
    "all_toks = []\n",
    "for extra_example in extra_examples:\n",
    "  subtoks = [vocab.bos_id()] + vocab.EncodeAsIds(extra_example)\n",
    "  subtoks = subtoks + [vocab.pad_id()] * (40 - len(subtoks))\n",
    "  all_toks.append(subtoks[:40])\n",
    "\n",
    "new_example_batch = pz.nx.wrap(\n",
    "    jnp.array(all_toks).astype(jnp.int32)\n",
    ").tag(\"batch\", \"seq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_tK0kh8R8Ccy"
   },
   "outputs": [],
   "source": [
    "token_visualization.show_token_array(new_example_batch, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "boF-StrT8dgI"
   },
   "outputs": [],
   "source": [
    "correct_next_token = new_example_batch[{\"seq\": pz.slice[1:]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aNUtnwwr8a3-"
   },
   "outputs": [],
   "source": [
    "orig_logits = model(new_example_batch)\n",
    "orig_log_probs = pz.nx.nmap(jax.nn.log_softmax)(orig_logits.untag(\"vocabulary\")).tag(\"vocabulary\")\n",
    "orig_sliced_preds = orig_log_probs[{\"seq\": pz.slice[:-1]}]\n",
    "orig_log_prob_of_correct_next = orig_sliced_preds[{\"vocabulary\": correct_next_token}]\n",
    "del orig_logits, orig_log_probs, orig_sliced_preds\n",
    "\n",
    "print(\"Original\")\n",
    "token_visualization.show_token_scores(\n",
    "    correct_next_token, pz.nx.nmap(jnp.exp)(orig_log_prob_of_correct_next), vocab, vmax=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WYNL9BBt8T1A"
   },
   "outputs": [],
   "source": [
    "ablated_logits = ablated_model(new_example_batch)\n",
    "ablated_log_probs = pz.nx.nmap(jax.nn.log_softmax)(ablated_logits.untag(\"vocabulary\")).tag(\"vocabulary\")\n",
    "ablated_sliced_preds = ablated_log_probs[{\"seq\": pz.slice[:-1]}]\n",
    "ablated_log_prob_of_correct_next = ablated_sliced_preds[{\"vocabulary\": correct_next_token}]\n",
    "del ablated_logits, ablated_log_probs, ablated_sliced_preds\n",
    "\n",
    "print(\"Ablated\")\n",
    "token_visualization.show_token_scores(\n",
    "    correct_next_token, pz.nx.nmap(jnp.exp)(ablated_log_prob_of_correct_next), vocab, vmax=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6eVG4wFh-Rou"
   },
   "outputs": [],
   "source": [
    "# Plot differences:\n",
    "treescope.render_array(\n",
    "    ablated_log_prob_of_correct_next - orig_log_prob_of_correct_next,\n",
    "    valid_mask=(correct_next_token != vocab.pad_id()),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7r7iOjzL_gWr"
   },
   "source": [
    "It looks like knocking out these heads does reduce accuracy for other number sequences. It also somewhat decreases accuracy for a sequence of random words. On the other hand, it seems to have very little effect on the other sentences, suggesting that the model is using a different mechanism for those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UV_dVrm5AzPC"
   },
   "source": [
    "Let's return to the digit sequences for now. We dropped out all of the attention heads at once; what about the effect of each of them individually?\n",
    "\n",
    "One way to figure this out would be to make a new ablated model copy with a different attention mask. We could try dropping out individual heads one-at-a-time and see what accuracy we get. Or we could try various combinations of heads.\n",
    "\n",
    "Another option would be to try an approach inspired by *attribution patching* [(Nanda 2023)](https://www.neelnanda.io/mechanistic-interpretability/attribution-patching#what-is-attribution-patching=): approximate the neural network as a linear function of the attention weights (ignoring nonlinear factors), and use automatic differentiation to figure out the gradients of the correct-token loss with respect to our knockout mask. In effect, what this does is tell us \"if we increased/decreased this attention head's influence *a little bit*, how much would that increase/decrease the final accuracy?\"\n",
    "\n",
    "Luckily, JAX makes this incredibly easy! We can simply ask for the gradient with respect to the patching mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jz3zDU33CyQl"
   },
   "outputs": [],
   "source": [
    "def get_ablated_avg_log_prob(head_mask, model, input_tokens, loss_mask):\n",
    "  ablated_model = knock_out_heads(model, head_mask)\n",
    "  ablated_logits = ablated_model(input_tokens)\n",
    "  ablated_log_probs = pz.nx.nmap(jax.nn.log_softmax)(ablated_logits.untag(\"vocabulary\")).tag(\"vocabulary\")\n",
    "  ablated_sliced_preds = ablated_log_probs[{\"seq\": pz.slice[:-1]}]\n",
    "  correct_next_token = input_tokens[{\"seq\": pz.slice[1:]}]\n",
    "  lp_correct = ablated_sliced_preds[{\"vocabulary\": correct_next_token}]\n",
    "  lp_correct = pz.nx.nmap(jnp.where)(loss_mask, lp_correct, 0.0)\n",
    "  return jnp.mean(lp_correct.untag(\"seq\").unwrap())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQ6HTtRbFhG6"
   },
   "source": [
    "Let's start from a fully-unablated model and see how much slightly-ablating each head hurts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WEBB_8dBDcUd"
   },
   "outputs": [],
   "source": [
    "# pz.variable_jit is a version of jax.jit that works with pz.Parameter and\n",
    "# pz.StateVariable instances\n",
    "accuracy_grads = pz.variable_jit(jax.grad(get_ablated_avg_log_prob, argnums=0))(\n",
    "    pz.nx.ones({\"blocks\": 28, \"heads\": 16}),\n",
    "    model,\n",
    "    token_seq,\n",
    "    # Focus on improvements to the second repetition\n",
    "    loss_mask=(pz.nx.arange(\"seq\", 40) > 21)\n",
    ")\n",
    "accuracy_grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHjR_soDFk_-"
   },
   "source": [
    "Focusing on the induction heads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iIPozk8OFoSD"
   },
   "outputs": [],
   "source": [
    "print(jnp.max((accuracy_grads * (1-top_heads_mask)).untag(\"blocks\", \"heads\").unwrap()))\n",
    "treescope.render_array(\n",
    "    accuracy_grads,\n",
    "    valid_mask=1-top_heads_mask\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUJ4hOl0GS9H"
   },
   "source": [
    "If we linearize around the un-ablated model, it looks like small changes to the attention weights don't actually do very much. What if we linearize around the ablated version?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RwrI7FVRE9i7"
   },
   "outputs": [],
   "source": [
    "accuracy_grads = pz.variable_jit(jax.grad(get_ablated_avg_log_prob, argnums=0))(\n",
    "    top_heads_mask,\n",
    "    model,\n",
    "    token_seq,\n",
    "    loss_mask=(pz.nx.arange(\"seq\", 40) > 21)\n",
    ")\n",
    "accuracy_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vmmC9HxnEvJU"
   },
   "outputs": [],
   "source": [
    "print(jnp.max((accuracy_grads * (1-top_heads_mask)).untag(\"blocks\", \"heads\").unwrap()))\n",
    "treescope.render_array(\n",
    "    accuracy_grads,\n",
    "    valid_mask=1-top_heads_mask\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhckWkjiG9QJ"
   },
   "source": [
    "In contrast, it looks like when we start from the ablated version, then adding back these heads has a big impact: if we add back $\\varepsilon$ of block21-head2, it increases the log-probability of correct tokens by by 1.75 $\\varepsilon$ on average!\n",
    "\n",
    "As Neel Nanda [notes](https://www.neelnanda.io/mechanistic-interpretability/attribution-patching#what-is-attribution-patching=), using a linear approximation can sometimes be misleading, especially if there are \"backup heads\" that take over when some heads are turned off. One conjecture about why we see such a big difference here is that these different attention heads may be compensating for each other, so that the difference between 9 and 10 heads doesn't matter much, but the difference between 0 and 1 head is critical.\n",
    "\n",
    "*Exercise for the reader: What's the smallest set of heads you need to drop out before the model stops being able to copy the integer digits well?*\n",
    "\n",
    "<details>\n",
    "<summary><i>Expand to see the answer</i></summary>\n",
    "\n",
    "If you run the ablation steps with different masks, you should find that masking out the following four heads causes the model to fail to solve the task:\n",
    "\n",
    "- Block 20, head 13  (index 0 of our sorted candidate array)\n",
    "- Block 21, head 1  (index 5 of our sorted candidate array)\n",
    "- Block 21, head 2  (index 3 of our sorted candidate array)\n",
    "- Block 21, head 5  (index 4 of our sorted candidate array)\n",
    "\n",
    "Adding back any of these heads makes it able to solve the task again!\n",
    "\n",
    "Interestingly, these four heads are also the four heads with the largest gradients starting from the fully-masked out condition above. So it's likely that these four heads are indeed compensating for each other.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnsO_lTMpxsj"
   },
   "source": [
    "### Path analysis with batched rewiring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KywtILaZSXH7"
   },
   "source": [
    "We've identified some induction heads, and verified that they are important for accurately copying repeated sequences of integer digits. But we might still wonder, *how* are these heads interacting with the rest of the model?\n",
    "\n",
    "- Are they directly adjust the residual stream in the direction of the correct token?\n",
    "- Are they telling other attention heads where to attend to?\n",
    "- Are they storing information used by later attention heads?\n",
    "- Are they copying information used by later MLP layers?\n",
    "\n",
    "Distinguishing these requires us to reason about the different *computation paths* that the model might be using.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJ0O75FhTRtr"
   },
   "source": [
    "In a library like [TransformerLens](https://github.com/neelnanda-io/TransformerLens), you might accomplish something like this by caching different activations across different runs of the model, and using mutable hooks to change which values get swapped out at each iteration (e.g. as described in [this path-patching tutorial by Callum McDougall](https://arena3-chapter1-transformer-interp.streamlit.app/[1.3]_Indirect_Object_Identification#731a1a66)). If you want, you can do something similar in Penzai, by saving the activations into mutable `pz.StateVariable` instances and then retrieving and swapping them out later.\n",
    "\n",
    "However, in Penzai, we can also use our model-editing powers to do this in a more declarative way. Instead of repeatedly running the model with different conditions, we'll run it once over a parallel set of \"counterfactual\" states, and add instructions for how to \"rewire\" them to separate the behavior of different computation paths.\n",
    "\n",
    "To see how this works, let's consider a simple subquestion. In very broad strokes, there are two possible ways each attention head could increase the probability of the correct token:\n",
    "- It could directly change the residual-stream embedding in a direction that increases the probability of the token,\n",
    "- or it could pass information to some later layer using the residual stream, and rely on some later part of the network to adjust the embedding.\n",
    "\n",
    "How could we distinguish between these? Suppose we made two copies of the residual stream. One copy (the \"indirect stream\") could be in charge of receiving the updates from each transformer block and passing them to the other blocks. The other (the \"direct stream\") could receive updates from all the other blocks and pass them to the final layer norm and unembedding layer. This decomposition is essentially the \"path expansion\" trick of Elhage et al. (2021).\n",
    "\n",
    "Now further suppose that we also made two copies of each block itself. Both copies would read from the indirect stream, but one would write to the direct stream and the other would write back to the indirect stream:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTgBWHiffhp4"
   },
   "source": [
    "\n",
    "```\n",
    "                                                                                                                    \n",
    "                   Indirect Stream                                                                                  \n",
    "               (+)(+)(+)                               \n",
    "                                                                                                             \n",
    "                                                                                                             \n",
    "                                                                   \n",
    " Input      Block 1      Block 2                Block L                                  \n",
    "    Embed            Copy A        Copy A                  Copy A                                 \n",
    "                                                                      \n",
    "                                                        ...                                                     \n",
    "                                                       \n",
    "                    Block 1       Block 2                 Block L       Output    Output  \n",
    "                        Copy B         Copy B                   Copy B     LayerNorm   Unembed    \n",
    "                                                      \n",
    "                                                                                                               \n",
    "                                                                                                               \n",
    "               (+)(+)(+)                             \n",
    "                   Direct Stream                                                                                    \n",
    "                                                                                                                    \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74tMjgZPfiNM"
   },
   "source": [
    "We could then separately ablate the induction heads in Copy B to see the effect of removing the direct path, or ablate them in Copy A to see the effect of removing them in the indirect path.\n",
    "\n",
    "Finally, we can apply one more trick: Let's think of Copy A and Copy B as being different *minibatch elements* of the same computation. In other words, let's add a new length-2 batch axis (let's call it \"worlds\") to our inputs and all of our intermediate values, such that `intermediate[{\"worlds\": 0}]` is the value this intermediate would have in the indirect stream or in copy A, and `intermediate[{\"worlds\": 1}]` is the value it would have in the direct stream or in copy B. Then we just need to make two changes to our model:\n",
    "- When we are applying our `KnockOutAttentionHeads` layer, we'll add a \"worlds\" axis to the mask. If we're ablating the direct path, `mask[{\"worlds\": 0}]` will be 1 everywhere, but `mask[{\"worlds\": 1}]` will have zeros at the parts we want to mask out.\n",
    "- Inside each residual block, before the layer norm, we'll add a new \"rewiring\" step where we copy `intermediate[{\"worlds\": 0}]` to `intermediate[{\"worlds\": 1}]`. This ensures that the \"Copy B\" versions still see the indirect stream as input, instead of reading the direct stream.\n",
    "\n",
    "Because Penzai models let you insert logic anywhere, and all of our model's layers vectorize over batch axes by name, these are both pretty easy to accomplish! We'll use a simple helper class to make it a bit clearer what we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NxZywef0J-nw"
   },
   "outputs": [],
   "source": [
    "@dataclasses.dataclass(frozen=True)\n",
    "class From:\n",
    "  \"\"\"A connection between two parallel computations.\"\"\"\n",
    "  source: str\n",
    "  weight: float | pz.nx.NamedArray = 1.0\n",
    "\n",
    "@pz.pytree_dataclass\n",
    "class RewireComputationPaths(pz.nn.Layer):\n",
    "  \"\"\"Rewires computation across parallel model runs along a \"worlds\"\" axis.\"\"\"\n",
    "  worlds_axis: str = dataclasses.field(metadata={\"pytree_node\": False})\n",
    "  world_ordering: tuple[str, ...] = dataclasses.field(metadata={\"pytree_node\": False})\n",
    "  taking: dict[str, From | tuple[From, ...]] = dataclasses.field(metadata={\"pytree_node\": False})\n",
    "\n",
    "  def path_matrix(self) -> pz.nx.NamedArray:\n",
    "    # Build a matrix that maps the \"from\" indices to the \"to\" indices as a\n",
    "    # linear operation.\n",
    "    result = [[0 for _ in self.world_ordering] for _ in self.world_ordering]\n",
    "    assert len(self.taking) == len(self.world_ordering)\n",
    "    assert set(self.taking.keys()) == set(self.world_ordering)\n",
    "    for dest, connections in self.taking.items():\n",
    "      if isinstance(connections, From):\n",
    "        connections = (connections,)\n",
    "      for connection in connections:\n",
    "        from_ix = self.world_ordering.index(connection.source)\n",
    "        to_ix = self.world_ordering.index(dest)\n",
    "        result[to_ix][from_ix] += connection.weight\n",
    "    return pz.nx.nmap(jnp.array)(result)  # <- Allows the weights to be named arrays\n",
    "\n",
    "  def __call__(self, inputs: pz.nx.NamedArray, **side_inputs) -> pz.nx.NamedArray:\n",
    "    mat = self.path_matrix().astype(inputs.dtype)\n",
    "    rewired = pz.nx.nmap(jnp.dot)(mat, inputs.untag(self.worlds_axis))\n",
    "    return rewired.tag(self.worlds_axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-I_eFj2lzYf"
   },
   "source": [
    "Here's how we could use it to rewire both worlds to read from the indirect stream:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ptyRvk08jBwh"
   },
   "outputs": [],
   "source": [
    "read_both_from_indirect = RewireComputationPaths(\n",
    "    worlds_axis=\"worlds\",\n",
    "    world_ordering=(\"indirect\", \"direct\"),\n",
    "    taking={\n",
    "        \"indirect\": From(\"indirect\"),\n",
    "        \"direct\": From(\"indirect\"),\n",
    "    }\n",
    ")\n",
    "pz.show(read_both_from_indirect)\n",
    "pz.show(read_both_from_indirect.path_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Luwv0n41mGJm"
   },
   "outputs": [],
   "source": [
    "%%autovisualize None\n",
    "read_both_from_indirect(pz.nx.wrap(jnp.array([123., 456.])).tag(\"worlds\")).untag(\"worlds\").unwrap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MtD737EGqisw"
   },
   "source": [
    "Now let's insert it into our model. We need to insert a rewiring layer every time the model reads from the residual stream, which in practice means we need to insert it in every residual block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "au4yNFC-rAZq"
   },
   "outputs": [],
   "source": [
    "world_ordering = (\"indirect\", \"direct\")\n",
    "rewired_model = (\n",
    "    pz.select(model)\n",
    "    .at_instances_of(pz.nn.Residual)\n",
    "    .at(lambda r: r.delta.sublayers[0])  # <- assuming each residual contains a Sequential\n",
    "    .insert_before(\n",
    "        RewireComputationPaths(\n",
    "            worlds_axis=\"worlds\",\n",
    "            world_ordering=world_ordering,\n",
    "            taking={\n",
    "                \"indirect\": From(\"indirect\"),\n",
    "                \"direct\": From(\"indirect\"),\n",
    "            },\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xdmA6GM0mR03"
   },
   "outputs": [],
   "source": [
    "%%autovisualize None\n",
    "pz.select(rewired_model).at_instances_of(RewireComputationPaths).show_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_N_r8XDsOld"
   },
   "source": [
    "If we run it right now, it should behave exactly the same as the original model, because we haven't actually done anything different across the two \"worlds\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7_D-MVMZqzFt"
   },
   "outputs": [],
   "source": [
    "rewired_logits = rewired_model(\n",
    "    pz.nx.stack([token_seq, token_seq], \"worlds\")\n",
    ")\n",
    "\n",
    "rewired_log_probs = pz.nx.nmap(jax.nn.log_softmax)(rewired_logits.untag(\"vocabulary\")).tag(\"vocabulary\")\n",
    "rewired_sliced_preds = rewired_log_probs[{\"seq\": pz.slice[:-1]}]\n",
    "correct_next_token = token_seq[{\"seq\": pz.slice[1:]}]\n",
    "lp_correct = rewired_sliced_preds[{\"vocabulary\": correct_next_token}]\n",
    "lp_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-ygVghKtTF9"
   },
   "source": [
    "Now let's try ablating the heads along one of the paths. We'll take the minimal set of induction heads we found in the previous section (in the \"exercise\"), and ablate their direct path; we'll still allow their output to be processed by the later layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2mkl6yUVuFMs"
   },
   "outputs": [],
   "source": [
    "per_world_head_mask = pz.nx.wrap(\n",
    "    jnp.ones(positional_avgs.shape + (2,), dtype=jnp.bfloat16)\n",
    "    .at[np.array([20,21,21,21]), np.array([13,1,2,5]), 1]\n",
    "    .set(0.0)\n",
    ").tag(\"blocks\", \"heads\", \"worlds\")\n",
    "treescope.render_array(\n",
    "    per_world_head_mask, axis_item_labels={\"worlds\": world_ordering}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bd_d0UhjtJCz"
   },
   "outputs": [],
   "source": [
    "ablated_rewired_model = knock_out_heads(rewired_model, per_world_head_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0AMKo00uo1j"
   },
   "outputs": [],
   "source": [
    "ablated_rewired_logits = ablated_rewired_model(\n",
    "    pz.nx.stack([token_seq, token_seq], \"worlds\")\n",
    ")\n",
    "\n",
    "ablated_rewired_log_probs = pz.nx.nmap(jax.nn.log_softmax)(\n",
    "    ablated_rewired_logits.untag(\"vocabulary\")\n",
    ").tag(\"vocabulary\")\n",
    "ablated_rewired_sliced_preds = ablated_rewired_log_probs[{\"seq\": pz.slice[:-1]}]\n",
    "correct_next_token = token_seq[{\"seq\": pz.slice[1:]}]\n",
    "lp_correct = ablated_rewired_sliced_preds[{\"vocabulary\": correct_next_token}]\n",
    "pz.nx.nmap(jnp.exp)(lp_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JifUJYZ8uyba"
   },
   "source": [
    "We can see that now there's a difference between the two \"worlds\"!\n",
    "\n",
    "Note that the intention of our experiment here was that only the \"direct\" path would matter, so it doesn't make a huge amount of sense to compare the outputs of both paths. However, we could alternatively think of the \"indirect\" path as being a \"unablated\" or \"clean\" path.\n",
    "\n",
    "The accuracy does seem to decrease a bit relative to the unablated version. But the model still seems to be doing an OK job at copying near the end of the sequence, so perhaps the model is using the indirect path to adjust the logits? Let's run a larger comparison to get a better sense.\n",
    "\n",
    "We'll run it again, but with four parallel worlds:\n",
    "\n",
    "- In the \"original\" world, we won't do any ablation or rewiring.\n",
    "- In the \"fully_ablated\" world, we'll ablate the four induction heads, but we won't do any rewiring.\n",
    "- In the \"original_ablate_direct\" world, we'll read from the \"original\" world, but we'll ablate the induction heads. Since none of the layers read from the \"original_ablate_direct\" world itself, it represents an ablated direct path from \"original\" to the output.\n",
    "- In the \"ablated_restore_direct\" world, we'll read from the \"fully_ablated\" world, but we'll turn the induction heads back on. Since none of the layers  read from the \"ablated_restore_direct\" world itself, it represents an unablated direct path from \"fully_ablated\" to the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d-79QqKWur8U"
   },
   "outputs": [],
   "source": [
    "world_ordering = (\n",
    "    \"original\",\n",
    "    \"original_ablate_direct\",\n",
    "    \"ablated_restore_direct\",\n",
    "    \"fully_ablated\",\n",
    ")\n",
    "\n",
    "ablate_critical_heads_mask = pz.nx.wrap(\n",
    "    jnp.ones(positional_avgs.shape, dtype=jnp.bfloat16)\n",
    "    .at[np.array([20,21,21,21]), np.array([13,1,2,5])]\n",
    "    .set(0.0)\n",
    ").tag(\"blocks\", \"heads\")\n",
    "unablated_mask = pz.nx.ones({\"blocks\": 28, \"heads\": 16})\n",
    "\n",
    "world_mask_map = {\n",
    "    \"original\": unablated_mask,\n",
    "    \"original_ablate_direct\": ablate_critical_heads_mask,\n",
    "    \"ablated_restore_direct\": unablated_mask,\n",
    "    \"fully_ablated\": ablate_critical_heads_mask,\n",
    "}\n",
    "\n",
    "per_world_head_mask = pz.nx.stack([\n",
    "    world_mask_map[world] for world in world_ordering\n",
    "], \"worlds\")\n",
    "\n",
    "treescope.render_array(\n",
    "    per_world_head_mask, axis_item_labels={\"worlds\": world_ordering}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hQmvxS-Ryqfl"
   },
   "outputs": [],
   "source": [
    "read_rewirer = RewireComputationPaths(\n",
    "    worlds_axis=\"worlds\",\n",
    "    world_ordering=world_ordering,\n",
    "    taking={\n",
    "        \"original\": From(\"original\"),\n",
    "        \"original_ablate_direct\": From(\"original\"),\n",
    "        \"fully_ablated\": From(\"fully_ablated\"),\n",
    "        \"ablated_restore_direct\": From(\"fully_ablated\"),\n",
    "    },\n",
    ")\n",
    "rewired_model = (\n",
    "    pz.select(model)\n",
    "    .at_instances_of(pz.nn.Residual)\n",
    "    .at(lambda r: r.delta.sublayers[0])  # <- assuming each residual contains a Sequential\n",
    "    .insert_before(read_rewirer)\n",
    ")\n",
    "ablated_rewired_model = knock_out_heads(rewired_model, per_world_head_mask)\n",
    "\n",
    "read_rewirer.path_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41WPCAl9yh9n"
   },
   "source": [
    "Let's run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1QK3xzLQyaN0"
   },
   "outputs": [],
   "source": [
    "ablated_rewired_logits = ablated_rewired_model(\n",
    "    pz.nx.stack([token_seq] * len(world_ordering), \"worlds\")\n",
    ")\n",
    "ablated_rewired_log_probs = pz.nx.nmap(jax.nn.log_softmax)(\n",
    "    ablated_rewired_logits.untag(\"vocabulary\")\n",
    ").tag(\"vocabulary\")\n",
    "ablated_rewired_sliced_preds = ablated_rewired_log_probs[{\"seq\": pz.slice[:-1]}]\n",
    "correct_next_token = token_seq[{\"seq\": pz.slice[1:]}]\n",
    "lp_correct = ablated_rewired_sliced_preds[{\"vocabulary\": correct_next_token}]\n",
    "\n",
    "treescope.render_array(\n",
    "    lp_correct,\n",
    "    axis_item_labels={\"worlds\": world_ordering}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n-7iAlo00wzo"
   },
   "outputs": [],
   "source": [
    "treescope.render_array(\n",
    "    pz.nx.nmap(jnp.exp)(lp_correct),\n",
    "    axis_item_labels={\"worlds\": world_ordering}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DkojRrQyylDs"
   },
   "outputs": [],
   "source": [
    "print(world_ordering)\n",
    "token_visualization.show_token_scores(\n",
    "    correct_next_token,\n",
    "    lp_correct,\n",
    "    vocab,\n",
    "    vmax=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SW5_7wR0Al3"
   },
   "source": [
    "Interestingly, it looks like we again have some sort of compensation behavior; the model is able to make accurate predictions using either path alone.\n",
    "\n",
    "It also looks like the probabilities may be interacting in a nonlinear way. Let's instead look at the logits themselves, before the softmax normalization. Since logits are invariant to constant shifts, we'll compare the logit of the correct answer to the average logit of all digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kUxijUfHY2J8"
   },
   "outputs": [],
   "source": [
    "digit_token_ids = pz.nx.wrap(vocab.EncodeAsIds(\"0123456789\")).tag(\"digits\")\n",
    "logits_per_digit = ablated_rewired_logits[{\"seq\": pz.slice[:-1]}][{\"vocabulary\": digit_token_ids}]\n",
    "logits_per_digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AUslUKOmZhsI"
   },
   "outputs": [],
   "source": [
    "avg_digit_logit = logits_per_digit.untag(\"digits\").mean()\n",
    "logit_digit_deltas = (logits_per_digit - avg_digit_logit)\n",
    "treescope.render_array(logit_digit_deltas, axis_item_labels={\"worlds\": world_ordering})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P51lmrsoYcyD"
   },
   "outputs": [],
   "source": [
    "logits_correct_relative = (\n",
    "    ablated_rewired_logits[{\"seq\": pz.slice[:-1]}][{\"vocabulary\": correct_next_token}]\n",
    "    - avg_digit_logit\n",
    ")\n",
    "logits_correct_relative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CGyOpT7RzDCO"
   },
   "outputs": [],
   "source": [
    "print(world_ordering)\n",
    "token_visualization.show_token_scores(\n",
    "    correct_next_token,\n",
    "    logits_correct_relative,\n",
    "    vocab,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TvZYQsAbDZ7"
   },
   "source": [
    "Hypothesis: Do these vectors form a parallelogram? In other words, can we linearly decompose the effects of the two paths? Let's try comparing differences between conditions (e.g. a difference of differences).\n",
    "\n",
    "If the effects of the direct and indirect paths are independent, we should expect the first two rows to be the same (showing the influence of the direct path), and the second two rows to also be the same (showing the influence of the indirect path):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n-5rHR4Bb43m"
   },
   "outputs": [],
   "source": [
    "pz.nx.stack([\n",
    "    # Influence of the direct path.\n",
    "    (\n",
    "        logits_correct_relative[{\"worlds\": world_ordering.index(\"original\")}]\n",
    "        - logits_correct_relative[{\"worlds\": world_ordering.index(\"original_ablate_direct\")}]\n",
    "    ),\n",
    "    (\n",
    "        logits_correct_relative[{\"worlds\": world_ordering.index(\"ablated_restore_direct\")}]\n",
    "        - logits_correct_relative[{\"worlds\": world_ordering.index(\"fully_ablated\")}]\n",
    "    ),\n",
    "    # Influence of the indirect path.\n",
    "    (\n",
    "        logits_correct_relative[{\"worlds\": world_ordering.index(\"original\")}]\n",
    "        - logits_correct_relative[{\"worlds\": world_ordering.index(\"ablated_restore_direct\")}]\n",
    "    ),\n",
    "    (\n",
    "        logits_correct_relative[{\"worlds\": world_ordering.index(\"original_ablate_direct\")}]\n",
    "        - logits_correct_relative[{\"worlds\": world_ordering.index(\"fully_ablated\")}]\n",
    "    ),\n",
    "], \"comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50m53FAZctGp"
   },
   "source": [
    "It's not exact, but it's fairly close. The differences are likely because of remaining nonlinear interactions. In particular:\n",
    "\n",
    "- We still have a final layer norm layer, which applies a nonlinear transformation by normalizing by the second moment of its input. That could adjust the logit values.\n",
    "- Our induction heads are split over two transformer blocks, block 20 and block 21. This introduces a path that we haven't accounted for: block 20's head could send a message to block 21's heads (through the indirect stream), and then block 21's heads use this to change their output (through the direct stream). This path is blocked by *both* of our interventions, because we're ablating all four heads at once; we either ablate block 20's message in the indirect stream or the response from block 21's heads in the direct stream.\n",
    "\n",
    "Overall, though, it seems that the *indirect* path is doing more to increase the logit for the correct next digit (relative to the other digits) than the direct path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNkzzWUryQkM"
   },
   "source": [
    "Let's do a bit more analysis to try to decompose this further. A few possible hypotheses for how the indirect path could work:\n",
    "\n",
    "- An MLP layer might be amplifying the output of the induction heads.\n",
    "  - Gemma uses GEGLU MLP layers, which have multiplicative interactions between two sets of features. So we could further decompose this into two cases: it could be amplifying the head's output in a linear way (e.g. using it only in the linear features) or amplifying it in a nonlinear way (e.g. using it in the \"gating\" features with a GELU activation).\n",
    "- Another attention head might be amplifying the output of induction heads.\n",
    "  - It could do this by attending to this token and copying its value in a linear way.\n",
    "  - It could also in principle do this by using the induction head outputs to modify the queries and the keys, changing how information is routed. (This seems a bit unlikely, because the induction heads have already moved the information into the right place, but it's possible.)\n",
    "- Or, it could be some combination of these.\n",
    "\n",
    "\n",
    "We can try to isolate the effects of these different paths with a more complex rewiring configuration, by progressively enabling more computation paths:\n",
    "\n",
    "- In the \"fully_ablated\" setting, we'll knock out the induction heads as before.\n",
    "- In the \"restore_direct\" setting, we'll restore the induction heads, but rewire every layer's input to read from the \"fully_ablated\" world. Thus, the only path from those induction heads is the direct path to the output.\n",
    "- In the \"restore_direct_attnvalue\" setting, we'll rewire the query and key heads of the attention blocks to read from the \"fully_ablated\" world (freezing the attention pattern), but we'll allow the value head to act normally. This additionally enables paths that pass through later attention heads without changing their attention pattern.\n",
    "- In the \"restore_direct_attnall\" setting, we'll further allow the query and key projections to see the output of the induction heads, allowing attention patterns to change.\n",
    "- In the \"restore_direct_attnall_linmlp\" setting, we'll start with \"restore_direct_attnall\", but we'll linearize the MLP layers around their values in the \"fully_ablated\" setting, and then evaluate them including the output of the induction heads (and of the attention circuits). This additionally enables linear paths through the MLP layers.\n",
    "- Finally, as before, we'll have an \"original\" setting where nothing is rewired to read from \"fully_ablated\", and both linear and nonlinear computation paths are included.\n",
    "\n",
    "By comparing the accuracies of each of these steps, we should be able to tell roughly how much adding each type of path improves the model's accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGcOLSqFvj_d"
   },
   "source": [
    "How should we linearize the MLP layers? One way to do this would be to capture intermediates, then build this linear approximation by hand. But there's an easier way, by combining Penzai's compositionality with JAX's function transformations. We'll use the following combinator layer, which splits its input into two, preprocesses each copy, linearizes its child layer around the first copy, and then evaluates that linear approximation at the second:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vrbEyLuTYlVY"
   },
   "outputs": [],
   "source": [
    "@pz.pytree_dataclass\n",
    "class LinearizeAndAdjust(pz.nn.Layer):\n",
    "  linearize_around: pz.nn.Layer\n",
    "  evaluate_at: pz.nn.Layer\n",
    "  target: pz.nn.Layer\n",
    "\n",
    "  def __call__(self, inputs, **side_inputs):\n",
    "    primal_point = self.linearize_around(inputs)\n",
    "    eval_point = self.evaluate_at(inputs)\n",
    "    # f(b) ~= f(a) + (b-a) f'(a)\n",
    "    tangent_in = jax.tree_util.tree_map(\n",
    "        lambda ppt, ept: (ept - ppt).order_like(ppt),\n",
    "        primal_point,\n",
    "        eval_point,\n",
    "        is_leaf=pz.nx.is_namedarray,\n",
    "    )\n",
    "    primal_out, tangent_out = jax.jvp(\n",
    "        self.target, (primal_point,), (tangent_in,)\n",
    "    )\n",
    "    return jax.tree_util.tree_map(\n",
    "        lambda p_out, t_out: p_out + t_out,\n",
    "        primal_out,\n",
    "        tangent_out,\n",
    "        is_leaf=pz.nx.is_namedarray,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8YhDAQwzgLv"
   },
   "source": [
    "We can now perform our analysis by applying a sequence of structural patches to the model, inserting rewiring and linearization points one at a time as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AEHhH-vLFMtl"
   },
   "outputs": [],
   "source": [
    "world_ordering = (\n",
    "    \"fully_ablated\",\n",
    "    \"restore_direct\",\n",
    "    \"restore_direct_attnvalue\",\n",
    "    \"restore_direct_attnall\",\n",
    "    \"restore_direct_attnall_linmlp\",\n",
    "    \"original\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1DJvTg4BGNHy"
   },
   "outputs": [],
   "source": [
    "# Set up the ablation of our attention heads, as before.\n",
    "ablate_critical_heads_mask = pz.nx.wrap(\n",
    "    jnp.ones(positional_avgs.shape, dtype=jnp.bfloat16)\n",
    "    .at[np.array([20,21,21,21]), np.array([13,1,2,5])]\n",
    "    .set(0.0)\n",
    ").tag(\"blocks\", \"heads\")\n",
    "unablated_mask = pz.nx.ones({\"blocks\": 28, \"heads\": 16})\n",
    "\n",
    "world_mask_map = {\n",
    "    \"fully_ablated\": ablate_critical_heads_mask,\n",
    "    \"restore_direct\": unablated_mask,\n",
    "    \"restore_direct_attnvalue\": unablated_mask,\n",
    "    \"restore_direct_attnall\": unablated_mask,\n",
    "    \"restore_direct_attnall_linmlp\": unablated_mask,\n",
    "    \"original\": unablated_mask,\n",
    "}\n",
    "per_world_head_mask = pz.nx.stack([\n",
    "    world_mask_map[world] for world in world_ordering\n",
    "], \"worlds\")\n",
    "\n",
    "treescope.render_array(\n",
    "    per_world_head_mask, axis_item_labels={\"worlds\": world_ordering}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oRO7GXHRrXsg"
   },
   "outputs": [],
   "source": [
    "# Start with the original unmodified model checkpoint.\n",
    "rewired_model = model\n",
    "\n",
    "# Linearize the final output layer norm around the ablated input.\n",
    "# This isn't strictly necessary, but it shouldn't affect the relative\n",
    "# differences between the logits much, and we aren't particularly interested in\n",
    "# the effect of this layer norm.\n",
    "rewired_model = (\n",
    "    pz.select(rewired_model)\n",
    "    .at(lambda root: root.body.sublayers[-2])\n",
    "    .apply(lambda layernorm_layer: LinearizeAndAdjust(\n",
    "        # Linearize around fully_ablated always\n",
    "        linearize_around=RewireComputationPaths(\n",
    "            worlds_axis=\"worlds\",\n",
    "            world_ordering=world_ordering,\n",
    "            taking={\n",
    "                k: From(\"fully_ablated\") for k in world_ordering\n",
    "            },\n",
    "        ),\n",
    "        # But evaluate it at each world's own input.\n",
    "        evaluate_at=pz.nn.Identity(),\n",
    "        target=layernorm_layer,\n",
    "    ))\n",
    ")\n",
    "\n",
    "# Knock out the attention heads using the mask we defined above.\n",
    "rewired_model = knock_out_heads(rewired_model, per_world_head_mask)\n",
    "\n",
    "# Rewire the attention queries and keys.\n",
    "rewired_model = (\n",
    "    pz.select(rewired_model)\n",
    "    .at_instances_of(pz.nn.Attention)\n",
    "    .at(lambda attn: (attn.input_to_query.sublayers[0], attn.input_to_key.sublayers[0]))\n",
    "    .insert_before(RewireComputationPaths(\n",
    "        worlds_axis=\"worlds\",\n",
    "        world_ordering=world_ordering,\n",
    "        taking={\n",
    "            # Ablating the induction head -> attention pattern paths\n",
    "            \"fully_ablated\": From(\"fully_ablated\"),\n",
    "            \"restore_direct\": From(\"fully_ablated\"),\n",
    "            \"restore_direct_attnvalue\": From(\"fully_ablated\"),\n",
    "            # Restoring the induction head -> attention pattern paths\n",
    "            \"restore_direct_attnall\": From(\"restore_direct_attnall\"),\n",
    "            \"restore_direct_attnall_linmlp\": From(\"restore_direct_attnall_linmlp\"),\n",
    "            \"original\": From(\"original\"),\n",
    "        },\n",
    "    ))\n",
    ")\n",
    "\n",
    "# Rewire the attention values.\n",
    "rewired_model = (\n",
    "    pz.select(rewired_model)\n",
    "    .at_instances_of(pz.nn.Attention)\n",
    "    .at(lambda attn: attn.input_to_value.sublayers[0])\n",
    "    .insert_before(RewireComputationPaths(\n",
    "        worlds_axis=\"worlds\",\n",
    "        world_ordering=world_ordering,\n",
    "        taking={\n",
    "            # Ablating the induction head -> attention value paths\n",
    "            \"fully_ablated\": From(\"fully_ablated\"),\n",
    "            \"restore_direct\": From(\"fully_ablated\"),\n",
    "            # Restoring the induction head -> attention value paths\n",
    "            \"restore_direct_attnvalue\": From(\"restore_direct_attnvalue\"),\n",
    "            \"restore_direct_attnall\": From(\"restore_direct_attnall\"),\n",
    "            \"restore_direct_attnall_linmlp\": From(\"restore_direct_attnall_linmlp\"),\n",
    "            \"original\": From(\"original\"),\n",
    "        },\n",
    "    ))\n",
    ")\n",
    "\n",
    "# Linearize and rewire the MLP blocks.\n",
    "rewired_model = (\n",
    "    pz.select(rewired_model)\n",
    "    .at_instances_of(transformer.model_parts.TransformerFeedForward)\n",
    "    .apply(lambda mlp: LinearizeAndAdjust(\n",
    "        linearize_around=RewireComputationPaths(\n",
    "            worlds_axis=\"worlds\",\n",
    "            world_ordering=world_ordering,\n",
    "            taking={\n",
    "                # Ablating the induction head -> MLP nonlinear paths\n",
    "                \"fully_ablated\": From(\"fully_ablated\"),\n",
    "                \"restore_direct\": From(\"fully_ablated\"),\n",
    "                \"restore_direct_attnvalue\": From(\"fully_ablated\"),\n",
    "                \"restore_direct_attnall\": From(\"fully_ablated\"),\n",
    "                \"restore_direct_attnall_linmlp\": From(\"fully_ablated\"),\n",
    "                # Restoring the induction head -> MLP nonlinear paths\n",
    "                \"original\": From(\"original\"),\n",
    "            },\n",
    "        ),\n",
    "        evaluate_at=RewireComputationPaths(\n",
    "            worlds_axis=\"worlds\",\n",
    "            world_ordering=world_ordering,\n",
    "            taking={\n",
    "                # Ablating the induction head -> MLP linear paths\n",
    "                \"fully_ablated\": From(\"fully_ablated\"),\n",
    "                \"restore_direct\": From(\"fully_ablated\"),\n",
    "                \"restore_direct_attnvalue\": From(\"fully_ablated\"),\n",
    "                \"restore_direct_attnall\": From(\"fully_ablated\"),\n",
    "                # Restoring the induction head -> MLP linear paths\n",
    "                \"restore_direct_attnall_linmlp\": From(\"restore_direct_attnall_linmlp\"),\n",
    "                \"original\": From(\"original\"),\n",
    "            },\n",
    "        ),\n",
    "        target=mlp,\n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1yCRyHybLNrQ"
   },
   "source": [
    "Let's look at the changes to make sure we patched the correct parts of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qQMrRb4lenRO"
   },
   "outputs": [],
   "source": [
    "%%autovisualize None\n",
    "pz.select(rewired_model).at_instances_of(RewireComputationPaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ld-61_e_LTQD"
   },
   "source": [
    "Looks right! Now we can run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IIpfP5pyLao9"
   },
   "outputs": [],
   "source": [
    "rewired_logits = rewired_model(\n",
    "    token_seq.broadcast_to(named_shape={\"worlds\": len(world_ordering)})\n",
    ")\n",
    "correct_next_token = token_seq[{\"seq\": pz.slice[1:]}]\n",
    "digit_token_ids = pz.nx.wrap(vocab.EncodeAsIds(\"0123456789\")).tag(\"digits\")\n",
    "logits_per_digit = rewired_logits[{\"seq\": pz.slice[:-1]}][{\"vocabulary\": digit_token_ids}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h77A-_ThLapE"
   },
   "outputs": [],
   "source": [
    "avg_digit_logit = logits_per_digit.untag(\"digits\").mean()\n",
    "logit_digit_deltas = (logits_per_digit - avg_digit_logit)\n",
    "treescope.render_array(logit_digit_deltas, axis_item_labels={\"worlds\": world_ordering})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VNtAy3I9LapE"
   },
   "outputs": [],
   "source": [
    "logits_correct_relative = (\n",
    "    rewired_logits[{\"seq\": pz.slice[:-1]}][{\"vocabulary\": correct_next_token}]\n",
    "    - avg_digit_logit\n",
    ")\n",
    "logits_correct_relative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98I592ughFhB"
   },
   "source": [
    "Summarizing the average relative logits over the second repetition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4z93zl0LVN6"
   },
   "outputs": [],
   "source": [
    "{\n",
    "    worldname: float(\n",
    "        logits_correct_relative[{\"worlds\": i, \"seq\": pz.slice[21:]}]\n",
    "        .untag(\"seq\").mean().unwrap()\n",
    "    )\n",
    "    for i, worldname in enumerate(world_ordering)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izpInc7jhhnL"
   },
   "source": [
    "To summarize:\n",
    "- Just restoring the direct path increases the (relative) logit of the correct answers a fair amount (by about 1.5), as we've seen before.\n",
    "- Additionally restoring the attention-value path yields another increase of about 1.1.\n",
    "- However, if we also restore the query-key circuit's effect on the attention patterns, the average logit score actually decreases by about 0.9. This suggests that changes to later attention patterns modulate *down* the effect of the induction heads.\n",
    "  - For this experiment's ablation masks, we're restoring all four heads, so this could have something to do with the interaction between block 20 and block 21 that we mentioned previously. Perhaps block 21's heads compensate for block 20's head being inactive, and copy less strongly if it's active.\n",
    "- When we restore the linear path throught the MLPs, we see a large increase in the logit score (about 3.7).\n",
    "  - This suggests that the MLPs are very sensitive to the copied value in the ablated setting.\n",
    "- When we restore the nonlinear path as well, this drops down again by about 1.7.\n",
    "  - Also, though the logits across the tokens become \"smoother\" across the sequence, varying less from token to token. For instance, the token at index 36 has an unusually small logit value in the ablated settings, but has a fairly normal predicted logit in the fully-restored condition.\n",
    "\n",
    "This suggests that both the attention-value circuits and linearized MLP paths are set up to amplify the values read by the induction heads, and then the query-key interactions and nonlinear MLP components are used to dampen the effect of these paths and calibrate their predictions, perhaps compensating for the redundancies between the four heads we found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8DkTV6100Ho"
   },
   "source": [
    "### Activation patching and counterfactual inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdhy4nB-B1sf"
   },
   "source": [
    "With only a minor change to this batched rewiring setup, we can also perform *activation patching* ([Meng et al. 2021](https://arxiv.org/abs/2202.05262)): copying a single activation between two different inputs to see if we can edit the model's behavior.\n",
    "\n",
    "If these are induction heads, we should expect that they are raising the probability of copying the token they attend to. We can test this out by constructing two sequences:\n",
    "- Sequence 1 will be a repeated sequence like we've used so far.\n",
    "- Sequence 2 will be a *different* random sequence without repetition.\n",
    "\n",
    "We can then run the model on sequence 1, but intervene on the *value projections* of our induction heads, so that they actually take the values from sequence 2. If we're right about how this circuit works, we should expect that the model will attempt to copy the prefix of sequence 2 as the completion of sequence 1.\n",
    "\n",
    "Let's try it out. We'll use a similar strategy to our rewiring before. Our rewiring will have three \"worlds\":\n",
    "  - In \"original\", we'll feed sequence 1 in normally.\n",
    "  - In \"nonrepeating\", we'll feed sequence 2 in normally.\n",
    "  - In \"patched_induction_values\", we'll feed in sequence 1, but we'll patch in the value heads from sequence 2 for the induction heads only. (Note that, since we're not sampling from the model, the model's output predictions don't make their way back to the inputs.)\n",
    "  \n",
    "The difference from our earlier rewirings: we won't be knocking out any induction heads; we'll leave them as-is. Instead, we'll change our *input* so that it's different in the different worlds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5QyDZq1duv-E"
   },
   "source": [
    "Let's start by preparing the sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pNfYS-w4vyxA"
   },
   "outputs": [],
   "source": [
    "world_ordering = (\"original\", \"nonrepeating\", \"patched_induction_values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5gdiNuays18y"
   },
   "outputs": [],
   "source": [
    "counterfactuals = [\n",
    "    \"01976954310149754605\" + \"01976954310149754605\",  # <- Our running example so far. This one will be a reference.\n",
    "    \"67717010284911166217\" + \"06302739717444079179\",  # <- A counterfactual non-repeating sequence.\n",
    "    \"01976954310149754605\" + \"01976954310149754605\",  # <- The first example again, but we'll patch this one's activations.\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qkZ2tGQ1t6Q_"
   },
   "outputs": [],
   "source": [
    "all_toks = []\n",
    "for cf_example in counterfactuals:\n",
    "  subtoks = [vocab.bos_id()] + vocab.EncodeAsIds(cf_example)\n",
    "  all_toks.append(subtoks)\n",
    "\n",
    "counterfactuals_batch = pz.nx.wrap(\n",
    "    jnp.array(all_toks).astype(jnp.int32)\n",
    ").tag(\"worlds\", \"seq\")  # <- Name it using the same \"worlds\" axis convention.\n",
    "\n",
    "token_visualization.show_token_array(counterfactuals_batch, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zYguxnMHuyJK"
   },
   "source": [
    "Now let's rewire the heads. To do that, we'll need a matrix that tells us which world each head should read from. We'll do it manually for each head this time (although we could also write a helper function like `knock_out_heads` if we were planning to try a bunch of different ablations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wnIII3ipDtbL"
   },
   "outputs": [],
   "source": [
    "block_20_induction_heads = pz.nx.wrap(jnp.zeros([16], dtype=jnp.bool_).at[13].set(True)).tag(\"heads\")\n",
    "block_21_induction_heads = pz.nx.wrap(jnp.zeros([16], dtype=jnp.bool_).at[np.array([1,2,5])].set(True)).tag(\"heads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h1FihqbrDzYB"
   },
   "outputs": [],
   "source": [
    "# Start with the original unmodified model checkpoint.\n",
    "rewired_model = model\n",
    "\n",
    "# Rewire the attention values in block 20 and 21:\n",
    "for block_index, induction_head_mask in [\n",
    "    (20, block_20_induction_heads),\n",
    "     (21, block_21_induction_heads),\n",
    "]:\n",
    "  rewired_model = (\n",
    "      pz.select(rewired_model)\n",
    "      .at_instances_of(transformer.model_parts.TransformerBlock)\n",
    "      .assert_count_is(28)\n",
    "      .pick_nth_selected(block_index)\n",
    "      .at_instances_of(pz.nn.Attention)\n",
    "      .at(lambda attn: attn.input_to_value.sublayers[-1])  # <- the value projections\n",
    "      .assert_count_is(1)\n",
    "      .insert_after(RewireComputationPaths(\n",
    "          worlds_axis=\"worlds\",\n",
    "          world_ordering=world_ordering,\n",
    "          taking={\n",
    "              \"original\": From(\"original\"),\n",
    "              \"nonrepeating\": From(\"nonrepeating\"),\n",
    "              \"patched_induction_values\": (\n",
    "                  # The induction heads read from \"nonrepeating\".\n",
    "                  From(\"nonrepeating\", weight=pz.nx.nmap(jnp.where)(induction_head_mask, 1., 0.)),\n",
    "                  # Everything other than the induction heads take values from \"patched_induction_values\".\n",
    "                  From(\"patched_induction_values\", weight=pz.nx.nmap(jnp.where)(induction_head_mask, 0., 1.)),\n",
    "              ),\n",
    "          },\n",
    "      ))\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IkSL8U5Xxlg8"
   },
   "outputs": [],
   "source": [
    "%%autovisualize None\n",
    "pz.select(rewired_model).at_instances_of(RewireComputationPaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4N0Lw_Fy5Hw"
   },
   "source": [
    "Now we can run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fKfny8qZyXqj"
   },
   "outputs": [],
   "source": [
    "paired_logits = rewired_model(\n",
    "    counterfactuals_batch\n",
    ")\n",
    "# Let's look at the token probabilities of each digit:\n",
    "all_probs = pz.nx.nmap(jax.nn.softmax)(paired_logits.untag(\"vocabulary\")).tag(\"vocabulary\")\n",
    "digit_token_ids = pz.nx.wrap(vocab.EncodeAsIds(\"0123456789\")).tag(\"digits\")\n",
    "digit_probs = all_probs[{\"vocabulary\": digit_token_ids}]\n",
    "\n",
    "treescope.render_array(digit_probs, axis_item_labels={\"worlds\": world_ordering}, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7otvgLU06VJ"
   },
   "source": [
    "In the \"patched_induction_values\" setting (the third facet), we see that the model is confidently predicting digits, but they are wrong! Let's compare with the one-hot encodings of the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AhqEike7zEfr"
   },
   "outputs": [],
   "source": [
    "treescope.render_array(\n",
    "    counterfactuals_batch == digit_token_ids,\n",
    "    axis_item_labels={\"worlds\": world_ordering},\n",
    "    vmax=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCJrCvdf1d-h"
   },
   "source": [
    "As we predicted, the model outputs for the second half of the \"patched_induction_values\" condition (bottom right) are copying the digits from the first half of the \"*nonrepeating*\" input (middle left)! The only way this information could have been transferred is through our rewiring layers, so this means we've succesfully intervened on the \"source\" of the model's copying information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dAnFM-R2Vnh"
   },
   "source": [
    "We can just as easily try alternative variants. For instance, let's try running the model on the \"nonrepeating\" sequence, but patch in the *attention pattern* from the repeating \"original\" sequence, and see if it tries to copy the prefix of the \"nonrepeating\" sequence even though there's no reason to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q2Q4jIt93E8y"
   },
   "outputs": [],
   "source": [
    "world_ordering = (\"original\", \"nonrepeating\", \"patched_ind_attn_pattern\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2gl_-Pu625sJ"
   },
   "outputs": [],
   "source": [
    "counterfactuals = [\n",
    "    \"01976954310149754605\" + \"01976954310149754605\",\n",
    "    \"67717010284911166217\" + \"06302739717444079179\",\n",
    "    \"67717010284911166217\" + \"06302739717444079179\",  # <- Patching the non-repeating sequence this time.\n",
    "]\n",
    "all_toks = []\n",
    "for cf_example in counterfactuals:\n",
    "  subtoks = [vocab.bos_id()] + vocab.EncodeAsIds(cf_example)\n",
    "  all_toks.append(subtoks)\n",
    "\n",
    "counterfactuals_batch = pz.nx.wrap(\n",
    "    jnp.array(all_toks).astype(jnp.int32)\n",
    ").tag(\"worlds\", \"seq\")  # <- Name it using the same \"worlds\" axis convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YjdGsonF1XLV"
   },
   "outputs": [],
   "source": [
    "# Start with the original unmodified model checkpoint.\n",
    "rewired_model = model\n",
    "\n",
    "# Rewire the attention values in block 20 and 21:\n",
    "for block_index, induction_head_mask in [\n",
    "    (20, block_20_induction_heads),\n",
    "    (21, block_21_induction_heads),\n",
    "]:\n",
    "  rewired_model = (\n",
    "      pz.select(rewired_model)\n",
    "      .at_instances_of(transformer.model_parts.TransformerBlock)\n",
    "      .assert_count_is(28)\n",
    "      .pick_nth_selected(block_index)\n",
    "      .at_instances_of(pz.nn.Attention)\n",
    "      .at(lambda attn: attn.query_key_to_attn.sublayers[-1])  # <- the softmax\n",
    "      .assert_count_is(1)\n",
    "      .insert_after(RewireComputationPaths(\n",
    "          worlds_axis=\"worlds\",\n",
    "          world_ordering=world_ordering,\n",
    "          taking={\n",
    "              \"original\": From(\"original\"),\n",
    "              \"nonrepeating\": From(\"nonrepeating\"),\n",
    "              \"patched_ind_attn_pattern\": (\n",
    "                  # The induction head patterns are patched from \"original\".\n",
    "                  From(\"original\", weight=pz.nx.nmap(jnp.where)(induction_head_mask, 1., 0.)),\n",
    "                  # Every other pattern is kept from \"patched_ind_attn_pattern\".\n",
    "                  From(\"patched_ind_attn_pattern\", weight=pz.nx.nmap(jnp.where)(induction_head_mask, 0., 1.)),\n",
    "              ),\n",
    "          },\n",
    "      ))\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pC-I-etC3-Ak"
   },
   "outputs": [],
   "source": [
    "%%autovisualize None\n",
    "pz.select(rewired_model).at_instances_of(RewireComputationPaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sl1WDaeq3dPG"
   },
   "source": [
    "Let's see what we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VwHlb3Db3b6t"
   },
   "outputs": [],
   "source": [
    "paired_logits = rewired_model(counterfactuals_batch)\n",
    "# Let's look at the token probabilities of each digit:\n",
    "all_probs = pz.nx.nmap(jax.nn.softmax)(paired_logits.untag(\"vocabulary\")).tag(\"vocabulary\")\n",
    "digit_token_ids = pz.nx.wrap(vocab.EncodeAsIds(\"0123456789\")).tag(\"digits\")\n",
    "digit_probs = all_probs[{\"vocabulary\": digit_token_ids}]\n",
    "\n",
    "treescope.render_array(digit_probs, axis_item_labels={\"worlds\": world_ordering}, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSq7r_lT4N-0"
   },
   "source": [
    "It looks like patching the attention patterns of the induction heads is *not enough* to get it to start copying confidently!. However, there's still a very faint pattern of copied digits in the third condition if you look closely. We can take a difference in log-probs to better emphasize this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hmAOEovL3gmD"
   },
   "outputs": [],
   "source": [
    "all_log_probs = pz.nx.nmap(jax.nn.softmax)(paired_logits.untag(\"vocabulary\")).tag(\"vocabulary\")\n",
    "digit_log_probs = all_log_probs[{\"vocabulary\": digit_token_ids}]\n",
    "diffs = digit_log_probs[{\"worlds\": 2}] - digit_log_probs[{\"worlds\": 1}]\n",
    "\n",
    "pz.show(\n",
    "    \"Relevant tokens to copy:\",\n",
    "    treescope.render_array(\n",
    "        counterfactuals_batch[{\"worlds\": 2, \"seq\": pz.slice[:21]}] == digit_token_ids,\n",
    "        vmax=1,\n",
    "    )\n",
    ")\n",
    "pz.show(\n",
    "    \"Differences between 'patched_ind_attn_pattern' and 'nonrepeating' log probs:\",\n",
    "    treescope.render_array(diffs, vmax=0.07)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsxmh2b457tv"
   },
   "source": [
    "What do these results mean? One conjecture is that there are separate copy-detection and copy-location circuits in this model:\n",
    "- Some circuit before block 20 is responsible for determining whether or not this sequence looks like it's copying.\n",
    "- If this feature is active, these induction heads copy the token value, and it is amplified and used as the model's prediction.\n",
    "- However, if this feature is inactive, the induction heads don't copy the value they attend to.\n",
    "  - Perhaps that value is zeroed out in the subspace of the input that they attend to.\n",
    "  - Or, perhaps that value is copied into an output value subspace, but some later MLP layers scrub it out before it arrives at the final unembedding layer.\n",
    "\n",
    "Let's test these last two hypotheses by coping *both* the attention pattern and the values of the attention head, instead of just copying the attention pattern. If the zeroing-out is happening in the input subspace, we'd expect copying the full attention output to restore the copying behavior (but it would now copy the first half of the *first* sequence, instead of copying from the nonrepeating sequence). But if the zeroing-out is happening using MLPs later in the model, we'd expect copying the full attention output to not make much difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EnKQH-I58FUW"
   },
   "outputs": [],
   "source": [
    "world_ordering = (\"original\", \"nonrepeating\", \"patched_ind_attn_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VGR1QUko75mm"
   },
   "outputs": [],
   "source": [
    "# Start with the original unmodified model checkpoint.\n",
    "rewired_model = model\n",
    "\n",
    "# Rewire the attention values in block 20 and 21:\n",
    "for block_index, induction_head_mask in [\n",
    "    (20, block_20_induction_heads),\n",
    "    (21, block_21_induction_heads),\n",
    "]:\n",
    "  rewirer_layer = RewireComputationPaths(\n",
    "      worlds_axis=\"worlds\",\n",
    "      world_ordering=world_ordering,\n",
    "      taking={\n",
    "          \"original\": From(\"original\"),\n",
    "          \"nonrepeating\": From(\"nonrepeating\"),\n",
    "          \"patched_ind_attn_output\": (\n",
    "              # The induction heads are patched from \"original\".\n",
    "              From(\"original\", weight=pz.nx.nmap(jnp.where)(induction_head_mask, 1., 0.)),\n",
    "              # Every other value is kept from \"patched_ind_attn_output\".\n",
    "              From(\"patched_ind_attn_output\", weight=pz.nx.nmap(jnp.where)(induction_head_mask, 0., 1.)),\n",
    "          ),\n",
    "      },\n",
    "  )\n",
    "  rewired_model = (\n",
    "      pz.select(rewired_model)\n",
    "      .at_instances_of(transformer.model_parts.TransformerBlock)\n",
    "      .assert_count_is(28)\n",
    "      .pick_nth_selected(block_index)\n",
    "      .at_instances_of(pz.nn.Attention)\n",
    "      .at(lambda attn: attn.input_to_value.sublayers[-1])  # <- the value projection\n",
    "      .assert_count_is(1)\n",
    "      .insert_after(rewirer_layer)\n",
    "  )\n",
    "  rewired_model = (\n",
    "      pz.select(rewired_model)\n",
    "      .at_instances_of(transformer.model_parts.TransformerBlock)\n",
    "      .assert_count_is(28)\n",
    "      .pick_nth_selected(block_index)\n",
    "      .at_instances_of(pz.nn.Attention)\n",
    "      .at(lambda attn: attn.query_key_to_attn.sublayers[-1])  # <- the softmax\n",
    "      .assert_count_is(1)\n",
    "      .insert_after(rewirer_layer)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-bp_JHwS8RE_"
   },
   "outputs": [],
   "source": [
    "%%autovisualize None\n",
    "pz.select(rewired_model).at_instances_of(RewireComputationPaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mg0YYdgk8JkM"
   },
   "outputs": [],
   "source": [
    "paired_logits = rewired_model(counterfactuals_batch)\n",
    "all_probs = pz.nx.nmap(jax.nn.softmax)(paired_logits.untag(\"vocabulary\")).tag(\"vocabulary\")\n",
    "digit_token_ids = pz.nx.wrap(vocab.EncodeAsIds(\"0123456789\")).tag(\"digits\")\n",
    "digit_probs = all_probs[{\"vocabulary\": digit_token_ids}]\n",
    "\n",
    "treescope.render_array(digit_probs, axis_item_labels={\"worlds\": world_ordering}, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xD-Vua479Lrh"
   },
   "source": [
    "Looks like this still doesn't produce copying behavior. So, the second hypothesis is more likely to be true: there are probably MLP layers that are scrubbing out the contributions of this attention head, or at least not amplifying it.\n",
    "\n",
    "In fact, this is consistent with the behavior we observed in the previous section! We observed that the induction heads were being modulated in a nonlinear fashion by the MLP layers, and that those MLP layers were locally highly sensitive to the output of the induction heads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "giz1iszlAhfW"
   },
   "source": [
    "## Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLw2GAHsBFOq"
   },
   "source": [
    "Summarizing what we've found:\n",
    "\n",
    "- When the model is given random integer digit sequences, it looks like there are induction heads in blocks 5, 14, 20, and 21. By ablating them, we determined that preserving at least one head from blocks 20 and 21 is both necessary and sufficient for the model to confidently copy digits from its input.\n",
    "- Ablating individual linear and nonlinear paths through the model revealed that there are contributions through the direct output of the layer, through later attention heads, and through MLPs. However, there is a nonlinear modulating effect from both later attention patterns and the nonlinear MLP activations.\n",
    "- Running activation patching between counterfactual inputs showed that, if the model has decided to copy, we can change *what* it copies by patching in the induction head value projections. This is causal evidence that the model is using those value projections to make its prediction.\n",
    "- On the other hand, we *can't* seem to make the model *decide* to copy by patching in the attention pattern of the induction heads, or by patching in both the attention pattern and the copied values. This suggests that the MLP layers may be playing a role in \"gating\" these induction heads, and determining whether those outputs make their way to the prediction.\n",
    "\n",
    "Along the way, we've demonstrated how to:\n",
    "- Look at all sorts of high-dimensional named-axis arrays using Penzai's autovisualizer and `treescope.render_array`, optionally adding useful annotations of our own to the tooltips,\n",
    "- Look at token sequences with the `token_visualization` tool\n",
    "- Visualize the structure of the pretrained Gemma model\n",
    "- Inject new logic into that model using `pz.select`\n",
    "- Use the named axis system to identify likely induction heads\n",
    "- Write our own patching logic to knock out attention heads\n",
    "- Run complex path-rewiring experiments in vectorized form by adding a \"worlds\" axis\n",
    "- Linearize MLPs and layer norm blocks around their activations in different parallel \"worlds\"\n",
    "- And combine these to perform causal interventions on different activations within the model and between different inputs.\n",
    "\n",
    "Overall, this notebook demonstrates the flexibility of the Penzai toolkit, and how easy it is to compose different ablations, reroute various activation paths in a declarative way, and quickly iterate on our analysis  without having to manage mutable state or manually cache different model activations. It's also worth emphasizing again that this model is sharded across multiple accelerator devices using the power of the XLA compiler, and that the computation across our parallel counterfactual \"worlds\" is also fully vectorized and parallelizable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mx8hrBe36ifU"
   },
   "source": [
    "There's clearly more interesting behavior to explore about these circuits, but we'll stop here and leave this exploration to the reader. Some interesting questions you might explore:\n",
    "\n",
    "- Can you design a set of rewirings that would identify whether the head in block 20 is indeed influencing the attention patterns in block 21?\n",
    "- Why is restoring any one of these heads is sufficient to restore the overall copying behavior we've observed?\n",
    "- What are the other induction heads (in block 5 and 14) doing, given that they aren't enough to implement the copying behavior on their own?\n",
    "- What part of the model is responsible for deciding when it should copy and when it shouldn't copy? Can you figure out a minimal set of activations we can patch in from the repeating sequence to trick the model into copying the non-repeating sequence?\n",
    "\n",
    "We also note that the components `KnockOutAttentionHeads`, `RewireComputationPaths`, and `LinearizeAndAdjust` used in this notebook are also available in Penzai under `penzai.toolshed.model_rewiring`, so you can use them in your own notebooks without copying their definitions. But don't feel limited by those layers! Penzai makes it easy to add custom logic to the models, so you can perform whatever modification you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pH9PIYX_AT10"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Induction Heads in Gemma 7B"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
